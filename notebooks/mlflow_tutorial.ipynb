{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.049343Z",
     "start_time": "2023-05-03T23:55:58.780532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -----------\r\n",
      "aiofiles                      22.1.0\r\n",
      "aiosqlite                     0.19.0\r\n",
      "alembic                       1.10.4\r\n",
      "altair                        4.2.2\r\n",
      "anyio                         3.6.2\r\n",
      "argon2-cffi                   21.3.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "asttokens                     2.2.1\r\n",
      "async-generator               1.10\r\n",
      "attrs                         22.2.0\r\n",
      "Babel                         2.12.1\r\n",
      "backcall                      0.2.0\r\n",
      "backports.functools-lru-cache 1.6.4\r\n",
      "beautifulsoup4                4.12.2\r\n",
      "bleach                        6.0.0\r\n",
      "blinker                       1.6.2\r\n",
      "bokeh                         3.1.0\r\n",
      "boltons                       23.0.0\r\n",
      "Bottleneck                    1.3.7\r\n",
      "brotlipy                      0.7.0\r\n",
      "cached-property               1.5.2\r\n",
      "certifi                       2022.12.7\r\n",
      "certipy                       0.1.3\r\n",
      "cffi                          1.15.1\r\n",
      "charset-normalizer            3.1.0\r\n",
      "click                         8.1.3\r\n",
      "cloudpickle                   2.2.1\r\n",
      "colorama                      0.4.6\r\n",
      "comm                          0.1.3\r\n",
      "conda                         23.3.1\r\n",
      "conda-package-handling        2.0.2\r\n",
      "conda_package_streaming       0.7.0\r\n",
      "contourpy                     1.0.7\r\n",
      "cryptography                  40.0.2\r\n",
      "cycler                        0.11.0\r\n",
      "Cython                        0.29.34\r\n",
      "cytoolz                       0.12.0\r\n",
      "dask                          2023.4.1\r\n",
      "databricks-cli                0.17.6\r\n",
      "debugpy                       1.6.7\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "dill                          0.3.6\r\n",
      "distributed                   2023.4.1\r\n",
      "docker                        6.0.1\r\n",
      "entrypoints                   0.4\r\n",
      "et-xmlfile                    1.1.0\r\n",
      "executing                     1.2.0\r\n",
      "fastjsonschema                2.16.3\r\n",
      "filelock                      3.12.0\r\n",
      "Flask                         2.3.2\r\n",
      "flit_core                     3.8.0\r\n",
      "fonttools                     4.39.3\r\n",
      "fsspec                        2023.4.0\r\n",
      "gitdb                         4.0.10\r\n",
      "GitPython                     3.1.31\r\n",
      "gmpy2                         2.1.2\r\n",
      "greenlet                      2.0.2\r\n",
      "gunicorn                      20.1.0\r\n",
      "h5py                          3.8.0\r\n",
      "idna                          3.4\r\n",
      "imagecodecs                   2023.1.23\r\n",
      "imageio                       2.28.0\r\n",
      "importlib-metadata            6.6.0\r\n",
      "importlib-resources           5.12.0\r\n",
      "ipykernel                     6.22.0\r\n",
      "ipympl                        0.9.3\r\n",
      "ipython                       8.13.1\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.0.6\r\n",
      "itsdangerous                  2.1.2\r\n",
      "jedi                          0.18.2\r\n",
      "Jinja2                        3.1.2\r\n",
      "joblib                        1.2.0\r\n",
      "json5                         0.9.5\r\n",
      "jsonpatch                     1.32\r\n",
      "jsonpointer                   2.0\r\n",
      "jsonschema                    4.17.3\r\n",
      "jupyter_client                8.2.0\r\n",
      "jupyter_core                  5.3.0\r\n",
      "jupyter-events                0.6.3\r\n",
      "jupyter_server                2.5.0\r\n",
      "jupyter_server_fileid         0.9.0\r\n",
      "jupyter-server-mathjax        0.2.6\r\n",
      "jupyter_server_terminals      0.4.4\r\n",
      "jupyter_server_ydoc           0.8.0\r\n",
      "jupyter-telemetry             0.1.0\r\n",
      "jupyter-ydoc                  0.2.3\r\n",
      "jupyterhub                    4.0.0\r\n",
      "jupyterlab                    3.6.3\r\n",
      "jupyterlab-git                0.41.0\r\n",
      "jupyterlab-pygments           0.2.2\r\n",
      "jupyterlab_server             2.22.1\r\n",
      "jupyterlab-widgets            3.0.7\r\n",
      "kiwisolver                    1.4.4\r\n",
      "lazy_loader                   0.2\r\n",
      "libmambapy                    1.4.2\r\n",
      "llvmlite                      0.39.1\r\n",
      "locket                        1.0.0\r\n",
      "lz4                           4.3.2\r\n",
      "Mako                          1.2.4\r\n",
      "mamba                         1.4.2\r\n",
      "Markdown                      3.4.3\r\n",
      "MarkupSafe                    2.1.2\r\n",
      "matplotlib                    3.7.1\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mistune                       2.0.5\r\n",
      "mlflow                        2.3.1\r\n",
      "mpmath                        1.3.0\r\n",
      "msgpack                       1.0.5\r\n",
      "munkres                       1.1.4\r\n",
      "nbclassic                     0.5.6\r\n",
      "nbclient                      0.7.4\r\n",
      "nbconvert                     7.3.1\r\n",
      "nbdime                        3.2.1\r\n",
      "nbformat                      5.8.0\r\n",
      "nest-asyncio                  1.5.6\r\n",
      "networkx                      3.1\r\n",
      "nltk                          3.5\r\n",
      "notebook                      6.5.4\r\n",
      "notebook_shim                 0.2.3\r\n",
      "numba                         0.56.4\r\n",
      "numexpr                       2.8.4\r\n",
      "numpy                         1.23.5\r\n",
      "oauthlib                      3.2.2\r\n",
      "openpyxl                      3.1.2\r\n",
      "packaging                     23.1\r\n",
      "pamela                        1.0.0\r\n",
      "pandas                        2.0.1\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.3\r\n",
      "partd                         1.4.0\r\n",
      "patsy                         0.5.3\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        9.5.0\r\n",
      "pip                           23.1.2\r\n",
      "pkgutil_resolve_name          1.3.10\r\n",
      "platformdirs                  3.5.0\r\n",
      "pluggy                        1.0.0\r\n",
      "pooch                         1.7.0\r\n",
      "prometheus-client             0.16.0\r\n",
      "prompt-toolkit                3.0.38\r\n",
      "protobuf                      4.21.12\r\n",
      "psutil                        5.9.5\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "py-cpuinfo                    9.0.0\r\n",
      "pyaml                         21.10.1\r\n",
      "pyarrow                       11.0.0\r\n",
      "pycosat                       0.6.4\r\n",
      "pycparser                     2.21\r\n",
      "pycurl                        7.45.1\r\n",
      "Pygments                      2.15.1\r\n",
      "PyJWT                         2.6.0\r\n",
      "pyOpenSSL                     23.1.1\r\n",
      "pyparsing                     3.0.9\r\n",
      "pyrsistent                    0.19.3\r\n",
      "PySocks                       1.7.1\r\n",
      "python-dateutil               2.8.2\r\n",
      "python-json-logger            2.0.7\r\n",
      "pytz                          2023.3\r\n",
      "PyWavelets                    1.4.1\r\n",
      "PyYAML                        6.0\r\n",
      "pyzmq                         25.0.2\r\n",
      "querystring-parser            1.2.4\r\n",
      "regex                         2023.5.5\r\n",
      "requests                      2.29.0\r\n",
      "rfc3339-validator             0.1.4\r\n",
      "rfc3986-validator             0.1.1\r\n",
      "ruamel.yaml                   0.17.21\r\n",
      "ruamel.yaml.clib              0.2.7\r\n",
      "scikit-image                  0.20.0\r\n",
      "scikit-learn                  1.2.2\r\n",
      "scikit-optimize               0.9.0\r\n",
      "scipy                         1.10.1\r\n",
      "seaborn                       0.12.2\r\n",
      "Send2Trash                    1.8.2\r\n",
      "setuptools                    67.7.2\r\n",
      "six                           1.16.0\r\n",
      "smmap                         3.0.5\r\n",
      "sniffio                       1.3.0\r\n",
      "sortedcontainers              2.4.0\r\n",
      "soupsieve                     2.3.2.post1\r\n",
      "SQLAlchemy                    2.0.11\r\n",
      "sqlparse                      0.4.4\r\n",
      "stack-data                    0.6.2\r\n",
      "statsmodels                   0.13.5\r\n",
      "sympy                         1.11.1\r\n",
      "tables                        3.8.0\r\n",
      "tabulate                      0.9.0\r\n",
      "tblib                         1.7.0\r\n",
      "terminado                     0.17.1\r\n",
      "threadpoolctl                 3.1.0\r\n",
      "tifffile                      2023.4.12\r\n",
      "tinycss2                      1.2.1\r\n",
      "tomli                         2.0.1\r\n",
      "toolz                         0.12.0\r\n",
      "torch                         2.0.0\r\n",
      "tornado                       6.3\r\n",
      "tqdm                          4.56.0\r\n",
      "traitlets                     5.9.0\r\n",
      "typing_extensions             4.5.0\r\n",
      "tzdata                        2023.3\r\n",
      "unicodedata2                  15.0.0\r\n",
      "urllib3                       1.26.15\r\n",
      "vaderSentiment                3.3.2\r\n",
      "wcwidth                       0.2.6\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              1.5.1\r\n",
      "Werkzeug                      2.3.3\r\n",
      "wheel                         0.40.0\r\n",
      "widgetsnbextension            4.0.7\r\n",
      "xlrd                          2.0.1\r\n",
      "xyzservices                   2023.2.0\r\n",
      "y-py                          0.5.9\r\n",
      "ypy-websocket                 0.8.2\r\n",
      "zict                          3.0.0\r\n",
      "zipp                          3.15.0\r\n",
      "zstandard                     0.19.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.068623Z",
     "start_time": "2023-05-03T23:56:00.051591Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T11:12:01.681597Z",
     "start_time": "2023-05-03T11:12:00.297070Z"
    }
   },
   "source": [
    "I like to create a virtual environment \n",
    "- python -m venv /path/to/new/virtual/environment\n",
    "- source python /path/to/new/virtual/environment/bin/activate"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# packages in environment at /Users/mahmoudnassar/miniconda3/envs/MLOps:\r\n",
      "#\r\n",
      "# Name                    Version                   Build  Channel\r\n",
      "alembic                   1.10.4             pyhd8ed1ab_0    conda-forge\r\n",
      "anyio                     3.5.0           py310hca03da5_0  \r\n",
      "appdirs                   1.4.4              pyhd3eb1b0_0  \r\n",
      "appnope                   0.1.2           py310hca03da5_1001  \r\n",
      "argon2-cffi               21.3.0             pyhd3eb1b0_0  \r\n",
      "argon2-cffi-bindings      21.2.0          py310h1a28f6b_0  \r\n",
      "asn1crypto                1.5.1              pyhd8ed1ab_0    conda-forge\r\n",
      "asttokens                 2.0.5              pyhd3eb1b0_0  \r\n",
      "attrs                     22.1.0          py310hca03da5_0  \r\n",
      "babel                     2.11.0          py310hca03da5_0  \r\n",
      "backcall                  0.2.0              pyhd3eb1b0_0  \r\n",
      "beautifulsoup4            4.12.2          py310hca03da5_0  \r\n",
      "blas                      1.0                    openblas  \r\n",
      "bleach                    4.1.0              pyhd3eb1b0_0  \r\n",
      "blinker                   1.6.2              pyhd8ed1ab_0    conda-forge\r\n",
      "bottleneck                1.3.5           py310h96f19d2_0  \r\n",
      "brotlipy                  0.7.0           py310h1a28f6b_1002  \r\n",
      "bzip2                     1.0.8                h620ffc9_4  \r\n",
      "ca-certificates           2022.12.7            h4653dfc_0    conda-forge\r\n",
      "certifi                   2022.12.7          pyhd8ed1ab_0    conda-forge\r\n",
      "cffi                      1.15.1          py310h80987f9_3  \r\n",
      "charset-normalizer        2.0.4              pyhd3eb1b0_0  \r\n",
      "click                     8.1.3           unix_pyhd8ed1ab_2    conda-forge\r\n",
      "cloudpickle               2.2.1              pyhd8ed1ab_0    conda-forge\r\n",
      "comm                      0.1.2           py310hca03da5_0  \r\n",
      "configparser              5.3.0              pyhd8ed1ab_0    conda-forge\r\n",
      "contourpy                 1.0.7                    pypi_0    pypi\r\n",
      "cryptography              39.0.1          py310h834c97f_0  \r\n",
      "cycler                    0.11.0                   pypi_0    pypi\r\n",
      "databricks-cli            0.17.6             pyhd8ed1ab_0    conda-forge\r\n",
      "debugpy                   1.5.1           py310hc377ac9_0  \r\n",
      "decorator                 5.1.1              pyhd3eb1b0_0  \r\n",
      "defusedxml                0.7.1              pyhd3eb1b0_0  \r\n",
      "docker                    6.0.1                    pypi_0    pypi\r\n",
      "docker-py                 5.0.3              pyhd8ed1ab_4    conda-forge\r\n",
      "docker-pycreds            0.4.0                      py_0    conda-forge\r\n",
      "entrypoints               0.4             py310hca03da5_0  \r\n",
      "executing                 0.8.3              pyhd3eb1b0_0  \r\n",
      "flask                     2.3.2              pyhd8ed1ab_0    conda-forge\r\n",
      "fonttools                 4.39.3                   pypi_0    pypi\r\n",
      "gettext                   0.21.0               h13f89a0_1  \r\n",
      "giflib                    5.2.1                h80987f9_3  \r\n",
      "gitdb                     4.0.10             pyhd8ed1ab_0    conda-forge\r\n",
      "gitpython                 3.1.31             pyhd8ed1ab_0    conda-forge\r\n",
      "glib                      2.69.1               h514c7bf_2  \r\n",
      "gorilla                   0.4.0              pyhd8ed1ab_0    conda-forge\r\n",
      "greenlet                  2.0.1           py310h313beb8_0  \r\n",
      "gst-plugins-base          1.14.1               h313beb8_1  \r\n",
      "gstreamer                 1.14.1               h80987f9_1  \r\n",
      "gunicorn                  20.1.0          py310hca03da5_0  \r\n",
      "icu                       68.1                 hc377ac9_0  \r\n",
      "idna                      3.4             py310hca03da5_0  \r\n",
      "importlib-metadata        6.6.0              pyha770c72_0    conda-forge\r\n",
      "importlib_resources       5.12.0             pyhd8ed1ab_0    conda-forge\r\n",
      "ipykernel                 6.19.2          py310h33ce5c2_0  \r\n",
      "ipython                   8.12.0          py310hca03da5_0  \r\n",
      "ipython_genutils          0.2.0              pyhd3eb1b0_1  \r\n",
      "ipywidgets                8.0.4           py310hca03da5_0  \r\n",
      "itsdangerous              2.1.2              pyhd8ed1ab_0    conda-forge\r\n",
      "jedi                      0.18.1          py310hca03da5_1  \r\n",
      "jinja2                    3.1.2           py310hca03da5_0  \r\n",
      "joblib                    1.1.1           py310hca03da5_0  \r\n",
      "jpeg                      9e                   h80987f9_1  \r\n",
      "json5                     0.9.6              pyhd3eb1b0_0  \r\n",
      "jsonschema                4.17.3          py310hca03da5_0  \r\n",
      "jupyter                   1.0.0           py310hca03da5_8  \r\n",
      "jupyter_client            8.1.0           py310hca03da5_0  \r\n",
      "jupyter_console           6.6.3           py310hca03da5_0  \r\n",
      "jupyter_core              5.3.0           py310hca03da5_0  \r\n",
      "jupyter_server            1.23.4          py310hca03da5_0  \r\n",
      "jupyterlab                3.5.3           py310hca03da5_0  \r\n",
      "jupyterlab_pygments       0.1.2                      py_0  \r\n",
      "jupyterlab_server         2.22.0          py310hca03da5_0  \r\n",
      "jupyterlab_widgets        3.0.5           py310hca03da5_0  \r\n",
      "kiwisolver                1.4.4                    pypi_0    pypi\r\n",
      "krb5                      1.19.4               h8380606_0  \r\n",
      "lerc                      3.0                  hc377ac9_0  \r\n",
      "libclang                  14.0.6          default_h1b80db6_1  \r\n",
      "libclang13                14.0.6          default_h24352ff_1  \r\n",
      "libcxx                    14.0.6               h848a8c0_0  \r\n",
      "libdeflate                1.17                 h80987f9_0  \r\n",
      "libedit                   3.1.20221030         h80987f9_0  \r\n",
      "libffi                    3.4.2                hca03da5_6  \r\n",
      "libgfortran               5.0.0           11_3_0_hca03da5_28  \r\n",
      "libgfortran5              11.3.0              h009349e_28  \r\n",
      "libiconv                  1.16                 h1a28f6b_2  \r\n",
      "libllvm14                 14.0.6               h7ec7a93_2  \r\n",
      "libopenblas               0.3.21               h269037a_0  \r\n",
      "libpng                    1.6.39               h80987f9_0  \r\n",
      "libpq                     12.9                 h65cfe13_3  \r\n",
      "libprotobuf               3.20.3               h514c7bf_0  \r\n",
      "libsodium                 1.0.18               h1a28f6b_0  \r\n",
      "libtiff                   4.5.0                h313beb8_2  \r\n",
      "libwebp                   1.2.4                ha3663a8_1  \r\n",
      "libwebp-base              1.2.4                h80987f9_1  \r\n",
      "libxml2                   2.10.3               h372ba2a_0  \r\n",
      "libxslt                   1.1.37               habca612_0  \r\n",
      "llvm-openmp               14.0.6               hc6e5704_0  \r\n",
      "lxml                      4.9.2           py310h80987f9_0  \r\n",
      "lz4-c                     1.9.4                h313beb8_0  \r\n",
      "mako                      1.2.4              pyhd8ed1ab_0    conda-forge\r\n",
      "markdown                  3.4.3                    pypi_0    pypi\r\n",
      "markupsafe                2.1.1           py310h1a28f6b_0  \r\n",
      "matplotlib                3.7.1                    pypi_0    pypi\r\n",
      "matplotlib-inline         0.1.6           py310hca03da5_0  \r\n",
      "mistune                   0.8.4           py310h1a28f6b_1000  \r\n",
      "mlflow                    1.2.0                      py_1    conda-forge\r\n",
      "nbclassic                 0.5.5           py310hca03da5_0  \r\n",
      "nbclient                  0.5.13          py310hca03da5_0  \r\n",
      "nbconvert                 6.5.4           py310hca03da5_0  \r\n",
      "nbformat                  5.7.0           py310hca03da5_0  \r\n",
      "ncurses                   6.4                  h313beb8_0  \r\n",
      "nest-asyncio              1.5.6           py310hca03da5_0  \r\n",
      "notebook                  6.5.4           py310hca03da5_0  \r\n",
      "notebook-shim             0.2.2           py310hca03da5_0  \r\n",
      "nspr                      4.33                 hc377ac9_0  \r\n",
      "nss                       3.74                 h142855e_0  \r\n",
      "numexpr                   2.8.4           py310hecc3335_0  \r\n",
      "numpy                     1.24.3          py310hb93e574_0  \r\n",
      "numpy-base                1.24.3          py310haf87e8b_0  \r\n",
      "oauthlib                  3.2.2              pyhd8ed1ab_0    conda-forge\r\n",
      "openssl                   1.1.1t               h03a7124_0    conda-forge\r\n",
      "packaging                 23.0            py310hca03da5_0  \r\n",
      "pandas                    2.0.1                    pypi_0    pypi\r\n",
      "pandocfilters             1.5.0              pyhd3eb1b0_0  \r\n",
      "parso                     0.8.3              pyhd3eb1b0_0  \r\n",
      "pcre                      8.45                 hc377ac9_0  \r\n",
      "pexpect                   4.8.0              pyhd3eb1b0_3  \r\n",
      "pickleshare               0.7.5           pyhd3eb1b0_1003  \r\n",
      "pillow                    9.5.0                    pypi_0    pypi\r\n",
      "pip                       23.0.1          py310hca03da5_0  \r\n",
      "platformdirs              2.5.2           py310hca03da5_0  \r\n",
      "ply                       3.11            py310hca03da5_0  \r\n",
      "pooch                     1.4.0              pyhd3eb1b0_0  \r\n",
      "prometheus_client         0.14.1          py310hca03da5_0  \r\n",
      "prompt-toolkit            3.0.36          py310hca03da5_0  \r\n",
      "prompt_toolkit            3.0.36               hd3eb1b0_0  \r\n",
      "protobuf                  4.22.3                   pypi_0    pypi\r\n",
      "psutil                    5.9.0           py310h1a28f6b_0  \r\n",
      "ptyprocess                0.7.0              pyhd3eb1b0_2  \r\n",
      "pure_eval                 0.2.2              pyhd3eb1b0_0  \r\n",
      "pyarrow                   11.0.0                   pypi_0    pypi\r\n",
      "pycparser                 2.21               pyhd3eb1b0_0  \r\n",
      "pygments                  2.11.2             pyhd3eb1b0_0  \r\n",
      "pyjwt                     2.6.0              pyhd8ed1ab_0    conda-forge\r\n",
      "pyopenssl                 23.0.0          py310hca03da5_0  \r\n",
      "pyparsing                 3.0.9              pyhd8ed1ab_0    conda-forge\r\n",
      "pyqt                      5.15.7          py310hc377ac9_0  \r\n",
      "pyqt5-sip                 12.11.0                  pypi_0    pypi\r\n",
      "pyrsistent                0.18.0          py310h1a28f6b_0  \r\n",
      "pysocks                   1.7.1           py310hca03da5_0  \r\n",
      "python                    3.10.11              hc0d8a6c_2  \r\n",
      "python-dateutil           2.8.2              pyhd3eb1b0_0  \r\n",
      "python-fastjsonschema     2.16.2          py310hca03da5_0  \r\n",
      "pytz                      2022.7          py310hca03da5_0  \r\n",
      "pywin32-on-windows        0.1.0              pyh1179c8e_3    conda-forge\r\n",
      "pyyaml                    6.0             py310h80987f9_1  \r\n",
      "pyzmq                     25.0.2          py310h313beb8_0  \r\n",
      "qt-main                   5.15.2               h8c8f68c_8  \r\n",
      "qt-webengine              5.15.9               h2903aaf_4  \r\n",
      "qtconsole                 5.4.2           py310hca03da5_0  \r\n",
      "qtpy                      2.2.0           py310hca03da5_0  \r\n",
      "qtwebkit                  5.212                h19f419d_5  \r\n",
      "querystring_parser        1.2.4                      py_0    conda-forge\r\n",
      "readline                  8.2                  h1a28f6b_0  \r\n",
      "requests                  2.29.0          py310hca03da5_0  \r\n",
      "scikit-learn              1.2.2           py310h313beb8_0  \r\n",
      "scipy                     1.10.1          py310h20cbe94_0  \r\n",
      "send2trash                1.8.0              pyhd3eb1b0_1  \r\n",
      "setuptools                66.0.0          py310hca03da5_0  \r\n",
      "simplejson                3.17.6          py310h1a28f6b_0  \r\n",
      "sip                       6.6.2           py310hc377ac9_0  \r\n",
      "six                       1.16.0             pyhd3eb1b0_1  \r\n",
      "smmap                     5.0.0                    pypi_0    pypi\r\n",
      "sniffio                   1.2.0           py310hca03da5_1  \r\n",
      "soupsieve                 2.4             py310hca03da5_0  \r\n",
      "sqlalchemy                2.0.12                   pypi_0    pypi\r\n",
      "sqlite                    3.41.2               h80987f9_0  \r\n",
      "sqlparse                  0.4.4              pyhd8ed1ab_0    conda-forge\r\n",
      "stack_data                0.2.0              pyhd3eb1b0_0  \r\n",
      "tabulate                  0.9.0              pyhd8ed1ab_1    conda-forge\r\n",
      "terminado                 0.17.1          py310hca03da5_0  \r\n",
      "threadpoolctl             2.2.0              pyh0d69192_0  \r\n",
      "tinycss2                  1.2.1           py310hca03da5_0  \r\n",
      "tk                        8.6.12               hb8d0fd4_0  \r\n",
      "toml                      0.10.2             pyhd3eb1b0_0  \r\n",
      "tomli                     2.0.1           py310hca03da5_0  \r\n",
      "tornado                   6.2             py310h1a28f6b_0  \r\n",
      "traitlets                 5.7.1           py310hca03da5_0  \r\n",
      "typing-extensions         4.5.0           py310hca03da5_0  \r\n",
      "typing_extensions         4.5.0           py310hca03da5_0  \r\n",
      "tzdata                    2023.3                   pypi_0    pypi\r\n",
      "urllib3                   1.26.15         py310hca03da5_0  \r\n",
      "wcwidth                   0.2.5              pyhd3eb1b0_0  \r\n",
      "webencodings              0.5.1           py310hca03da5_1  \r\n",
      "websocket-client          0.58.0          py310hca03da5_4  \r\n",
      "werkzeug                  2.3.3              pyhd8ed1ab_0    conda-forge\r\n",
      "wheel                     0.38.4          py310hca03da5_0  \r\n",
      "widgetsnbextension        4.0.5           py310hca03da5_0  \r\n",
      "xz                        5.2.10               h80987f9_1  \r\n",
      "yaml                      0.2.5                h3422bc3_2    conda-forge\r\n",
      "zeromq                    4.3.4                hc377ac9_0  \r\n",
      "zipp                      3.15.0             pyhd8ed1ab_0    conda-forge\r\n",
      "zlib                      1.2.13               h5a0b063_0  \r\n",
      "zstd                      1.5.5                hd90d995_0  \r\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of things like the hyperparameters and the metrics you’ve got. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the tunnel with mlflow command in the command line and specify where you want to save your artifacts\n",
    "if you want also the database add     --backend-store-uri sqlite:///mlflow.db \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T11:40:38.760748Z",
     "start_time": "2023-05-03T11:40:38.739408Z"
    }
   },
   "source": [
    "mlflow server \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --artifacts-destination /home/nuno/Desktop/NovaIMS/mlflow_project/ml_artifacts\\\n",
    "    --default-artifact-root /home/nuno/Desktop/NovaIMS/mlflow_project/ml_artifacts"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.102221Z",
     "start_time": "2023-05-03T23:56:00.071202Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.114114Z",
     "start_time": "2023-05-03T23:56:00.086814Z"
    }
   },
   "outputs": [],
   "source": [
    "# descrition that will be used as metadata\n",
    "description = \"the simplest possible example\"\n",
    "\n",
    "# Mlflow tracking server\n",
    "mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/03 23:56:00 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_first_example' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Experiment: artifact_location='/home/jovyan/mlruns/616838658831017469', creation_time=1683158160326, experiment_id='616838658831017469', last_update_time=1683158160326, lifecycle_stage='active', name='mlflow_first_example', tags={}>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"mlflow_first_example\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.360390Z",
     "start_time": "2023-05-03T23:56:00.102596Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:00.833194Z",
     "start_time": "2023-05-03T23:56:00.369116Z"
    }
   },
   "outputs": [],
   "source": [
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"tracking experiment_1\", description=description) as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:01.746100Z",
     "start_time": "2023-05-03T18:11:01.027764Z"
    }
   },
   "source": [
    "Runs are grouped into experiments. Each run can contain, for example, a different set of hyperparameters. Also, if you don’t specify an experiment name, the run you’re currently executing will be recorded under the Default experiment, which is created automatically by MLflow for you. Let's change to another name"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:01.148951Z",
     "start_time": "2023-05-03T23:56:00.799632Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"mlflow_first_example\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"params_no_artifacts_logged\") as run:\n",
    "\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.8)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:01.488935Z",
     "start_time": "2023-05-03T23:56:01.150919Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"params_no_artifacts_logged\") as run:\n",
    "\n",
    "    params = {\"n_estimators\":120, \"max_depth\":3, \"max_features\":6}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test2\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.9)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag_2\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:01.738613Z",
     "start_time": "2023-05-03T23:56:01.472225Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    params = {\"n_estimators\":120, \"max_depth\":3, \"max_features\":6}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test2\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.9)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag_2\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:05.221928Z",
     "start_time": "2023-05-03T18:11:04.536224Z"
    }
   },
   "source": [
    "And we can save the model"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:06.127500Z",
     "start_time": "2023-05-03T23:56:01.741307Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"real_model_to_save\") as run:\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=rf,\n",
    "    artifact_path=\"real_model_to_save\",\n",
    "  )\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:09.429731Z",
     "start_time": "2023-05-03T18:11:06.168881Z"
    }
   },
   "source": [
    "You now have not only your trained model managed for you (the model.pkl file), but you also have it’s dependencies automatically captured in three different flavours, i.e. conda.yaml, python_env.yaml and requirements.txt"
   ],
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/app'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[11], line 8\u001B[0m\n\u001B[1;32m      5\u001B[0m     rf\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m      7\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_params(params)\n\u001B[0;32m----> 8\u001B[0m     \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msklearn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m    \u001B[49m\u001B[43msk_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m    \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrandom_forest_regressor\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[1;32m     11\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     12\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mend_run()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:424\u001B[0m, in \u001B[0;36mlog_model\u001B[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS\u001B[38;5;241m.\u001B[39mformat(package_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_model\u001B[39m(\n\u001B[1;32m    333\u001B[0m     sk_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    345\u001B[0m     metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    346\u001B[0m ):\n\u001B[1;32m    347\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;124;03m    containing the following flavors:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m        mlflow.sklearn.log_model(sk_model, \"sk_models\")\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mflavor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msklearn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43msk_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msk_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconda_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconda_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcode_paths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserialization_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserialization_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mawait_registration_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mawait_registration_for\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/models/model.py:548\u001B[0m, in \u001B[0;36mModel.log\u001B[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    546\u001B[0m mlflow_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(artifact_path\u001B[38;5;241m=\u001B[39martifact_path, run_id\u001B[38;5;241m=\u001B[39mrun_id, metadata\u001B[38;5;241m=\u001B[39mmetadata)\n\u001B[1;32m    547\u001B[0m flavor\u001B[38;5;241m.\u001B[39msave_model(path\u001B[38;5;241m=\u001B[39mlocal_path, mlflow_model\u001B[38;5;241m=\u001B[39mmlflow_model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 548\u001B[0m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtracking\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfluent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmlflow_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    550\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mtracking\u001B[38;5;241m.\u001B[39mfluent\u001B[38;5;241m.\u001B[39m_record_logged_model(mlflow_model)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/fluent.py:818\u001B[0m, in \u001B[0;36mlog_artifacts\u001B[0;34m(local_dir, artifact_path)\u001B[0m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;124;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001B[39;00m\n\u001B[1;32m    790\u001B[0m \u001B[38;5;124;03mthis method will create a new active run.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;124;03m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001B[39;00m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    817\u001B[0m run_id \u001B[38;5;241m=\u001B[39m _get_or_start_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[0;32m--> 818\u001B[0m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/client.py:1074\u001B[0m, in \u001B[0;36mMlflowClient.log_artifacts\u001B[0;34m(self, run_id, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_artifacts\u001B[39m(\n\u001B[1;32m   1031\u001B[0m     \u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, local_dir: \u001B[38;5;28mstr\u001B[39m, artifact_path: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1032\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;124;03m    Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;124;03m        is_dir: True\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1074\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tracking_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:448\u001B[0m, in \u001B[0;36mTrackingServiceClient.log_artifacts\u001B[0;34m(self, run_id, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_artifacts\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_id, local_dir, artifact_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    442\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;124;03m    Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[1;32m    444\u001B[0m \n\u001B[1;32m    445\u001B[0m \u001B[38;5;124;03m    :param local_dir: Path to the directory of files to write.\u001B[39;00m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;124;03m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001B[39;00m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 448\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_artifact_repo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:57\u001B[0m, in \u001B[0;36mLocalArtifactRepository.log_artifacts\u001B[0;34m(self, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m     53\u001B[0m artifact_dir \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     54\u001B[0m     os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39martifact_dir, artifact_path) \u001B[38;5;28;01mif\u001B[39;00m artifact_path \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39martifact_dir\n\u001B[1;32m     55\u001B[0m )\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(artifact_dir):\n\u001B[0;32m---> 57\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m dir_util\u001B[38;5;241m.\u001B[39mcopy_tree(src\u001B[38;5;241m=\u001B[39mlocal_dir, dst\u001B[38;5;241m=\u001B[39martifact_dir, preserve_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, preserve_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/file_utils.py:122\u001B[0m, in \u001B[0;36mmkdir\u001B[0;34m(root, name)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m!=\u001B[39m errno\u001B[38;5;241m.\u001B[39mEEXIST \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(target):\n\u001B[0;32m--> 122\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m target\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/file_utils.py:119\u001B[0m, in \u001B[0;36mmkdir\u001B[0;34m(root, name)\u001B[0m\n\u001B[1;32m    117\u001B[0m target \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, name) \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m root\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 119\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m!=\u001B[39m errno\u001B[38;5;241m.\u001B[39mEEXIST \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(target):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: makedirs at line 215 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[0;31mPermissionError\u001B[0m: [Errno 13] Permission denied: '/app'"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also log an input example alongside the artifacts so that, for example, anyone could test a deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:06.142835Z",
     "start_time": "2023-05-03T23:56:06.140466Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:06.221024Z",
     "start_time": "2023-05-03T23:56:06.145428Z"
    }
   },
   "outputs": [],
   "source": [
    "signature = infer_signature(X_train, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:06.221563Z",
     "start_time": "2023-05-03T23:56:06.189032Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:11.253426Z",
     "start_time": "2023-05-03T23:56:06.213742Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"artifact_run_sign\") as run:\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "    \n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    signature = infer_signature(X_train, rf.predict(X_test))\n",
    "    input_example = X_train[0]\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf,\n",
    "        artifact_path=\"random_forest_regressor\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "  )\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:01:34.166519Z",
     "start_time": "2023-05-03T18:01:31.343774Z"
    }
   },
   "source": [
    "Instead of explicitily giving the arguments for mlflow log, there is a nice function to the autolog:"
   ],
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/app'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPermissionError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 10\u001B[0m\n\u001B[1;32m      8\u001B[0m     input_example \u001B[38;5;241m=\u001B[39m X_train[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mlog_params(params)\n\u001B[0;32m---> 10\u001B[0m     \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msklearn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_model\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     11\u001B[0m \u001B[43m        \u001B[49m\u001B[43msk_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     12\u001B[0m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mrandom_forest_regressor\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msignature\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mend_run()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:424\u001B[0m, in \u001B[0;36mlog_model\u001B[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS\u001B[38;5;241m.\u001B[39mformat(package_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_model\u001B[39m(\n\u001B[1;32m    333\u001B[0m     sk_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    345\u001B[0m     metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    346\u001B[0m ):\n\u001B[1;32m    347\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;124;03m    containing the following flavors:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m        mlflow.sklearn.log_model(sk_model, \"sk_models\")\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mflavor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msklearn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43msk_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msk_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconda_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconda_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcode_paths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserialization_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserialization_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mawait_registration_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mawait_registration_for\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/models/model.py:548\u001B[0m, in \u001B[0;36mModel.log\u001B[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    546\u001B[0m mlflow_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(artifact_path\u001B[38;5;241m=\u001B[39martifact_path, run_id\u001B[38;5;241m=\u001B[39mrun_id, metadata\u001B[38;5;241m=\u001B[39mmetadata)\n\u001B[1;32m    547\u001B[0m flavor\u001B[38;5;241m.\u001B[39msave_model(path\u001B[38;5;241m=\u001B[39mlocal_path, mlflow_model\u001B[38;5;241m=\u001B[39mmlflow_model, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m--> 548\u001B[0m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtracking\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfluent\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmlflow_model\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    550\u001B[0m     mlflow\u001B[38;5;241m.\u001B[39mtracking\u001B[38;5;241m.\u001B[39mfluent\u001B[38;5;241m.\u001B[39m_record_logged_model(mlflow_model)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/fluent.py:818\u001B[0m, in \u001B[0;36mlog_artifacts\u001B[0;34m(local_dir, artifact_path)\u001B[0m\n\u001B[1;32m    788\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    789\u001B[0m \u001B[38;5;124;03mLog all the contents of a local directory as artifacts of the run. If no run is active,\u001B[39;00m\n\u001B[1;32m    790\u001B[0m \u001B[38;5;124;03mthis method will create a new active run.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    815\u001B[0m \u001B[38;5;124;03m        mlflow.log_artifacts(\"data\", artifact_path=\"states\")\u001B[39;00m\n\u001B[1;32m    816\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    817\u001B[0m run_id \u001B[38;5;241m=\u001B[39m _get_or_start_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[0;32m--> 818\u001B[0m \u001B[43mMlflowClient\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/client.py:1074\u001B[0m, in \u001B[0;36mMlflowClient.log_artifacts\u001B[0;34m(self, run_id, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m   1030\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_artifacts\u001B[39m(\n\u001B[1;32m   1031\u001B[0m     \u001B[38;5;28mself\u001B[39m, run_id: \u001B[38;5;28mstr\u001B[39m, local_dir: \u001B[38;5;28mstr\u001B[39m, artifact_path: Optional[\u001B[38;5;28mstr\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1032\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1033\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1034\u001B[0m \u001B[38;5;124;03m    Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[1;32m   1035\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1072\u001B[0m \u001B[38;5;124;03m        is_dir: True\u001B[39;00m\n\u001B[1;32m   1073\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1074\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_tracking_client\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/_tracking_service/client.py:448\u001B[0m, in \u001B[0;36mTrackingServiceClient.log_artifacts\u001B[0;34m(self, run_id, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m    441\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_artifacts\u001B[39m(\u001B[38;5;28mself\u001B[39m, run_id, local_dir, artifact_path\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    442\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    443\u001B[0m \u001B[38;5;124;03m    Write a directory of files to the remote ``artifact_uri``.\u001B[39;00m\n\u001B[1;32m    444\u001B[0m \n\u001B[1;32m    445\u001B[0m \u001B[38;5;124;03m    :param local_dir: Path to the directory of files to write.\u001B[39;00m\n\u001B[1;32m    446\u001B[0m \u001B[38;5;124;03m    :param artifact_path: If provided, the directory in ``artifact_uri`` to write to.\u001B[39;00m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 448\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_artifact_repo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrun_id\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_artifacts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mlocal_dir\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/local_artifact_repo.py:57\u001B[0m, in \u001B[0;36mLocalArtifactRepository.log_artifacts\u001B[0;34m(self, local_dir, artifact_path)\u001B[0m\n\u001B[1;32m     53\u001B[0m artifact_dir \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     54\u001B[0m     os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39martifact_dir, artifact_path) \u001B[38;5;28;01mif\u001B[39;00m artifact_path \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39martifact_dir\n\u001B[1;32m     55\u001B[0m )\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(artifact_dir):\n\u001B[0;32m---> 57\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_dir\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     58\u001B[0m dir_util\u001B[38;5;241m.\u001B[39mcopy_tree(src\u001B[38;5;241m=\u001B[39mlocal_dir, dst\u001B[38;5;241m=\u001B[39martifact_dir, preserve_mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, preserve_times\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/file_utils.py:122\u001B[0m, in \u001B[0;36mmkdir\u001B[0;34m(root, name)\u001B[0m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m!=\u001B[39m errno\u001B[38;5;241m.\u001B[39mEEXIST \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(target):\n\u001B[0;32m--> 122\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m e\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m target\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/file_utils.py:119\u001B[0m, in \u001B[0;36mmkdir\u001B[0;34m(root, name)\u001B[0m\n\u001B[1;32m    117\u001B[0m target \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(root, name) \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m root\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 119\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m e\u001B[38;5;241m.\u001B[39merrno \u001B[38;5;241m!=\u001B[39m errno\u001B[38;5;241m.\u001B[39mEEXIST \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39misdir(target):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "    \u001B[0;31m[... skipping similar frames: makedirs at line 215 (2 times)]\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    213\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m head \u001B[38;5;129;01mand\u001B[39;00m tail \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists(head):\n\u001B[1;32m    214\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 215\u001B[0m         \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    216\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[1;32m    217\u001B[0m         \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n\u001B[1;32m    218\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[0;34m(name, mode, exist_ok)\u001B[0m\n\u001B[1;32m    223\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[1;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[1;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n\u001B[1;32m    229\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m exist_ok \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m path\u001B[38;5;241m.\u001B[39misdir(name):\n",
      "\u001B[0;31mPermissionError\u001B[0m: [Errno 13] Permission denied: '/app'"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:16.389Z",
     "start_time": "2023-05-03T23:56:11.236923Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/03 23:56:11 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_tracking_with_autolog' does not exist. Creating a new experiment.\n",
      "2023/05/03 23:56:12 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/05/03 23:56:12 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'bcd260fe9f96403f852ae85d92bd38be', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_with_autolog\")\n",
    "\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "# train the model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "with mlflow.start_run(run_name=\"run_2\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T18:01:34.166270Z"
    }
   },
   "source": [
    "Librarires that support autologging:\n",
    "\n",
    "- Scikit-learn\n",
    "\n",
    "- Keras\n",
    "\n",
    "- Gluon\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- Statsmodels\n",
    "\n",
    "- Spark\n",
    "\n",
    "- Fastai\n",
    "\n",
    "- Pytorch"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to test different parameters, we can use a nested run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T23:56:22.190684Z",
     "start_time": "2023-05-03T23:56:16.379314Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"main_run_for_nested\") as run:\n",
    "    for estimators in range(20, 100, 20):\n",
    "        with mlflow.start_run(run_name=f\"nested_{estimators}_estimators\", nested=True) as nested:\n",
    "            rf = RandomForestRegressor(n_estimators=estimators, max_depth=6, max_features=3)\n",
    "            rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving our code with  hyperparameter fine-tunning:"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:01:33.778820Z",
     "start_time": "2023-05-03T23:56:22.199145Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/03 23:57:31 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 3beb655702434b0d9d230e97a6140e64. Failed operations: [MlflowException(\"API request to http://mlflow-starter-server:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'mlflow-starter-server\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n",
      "2023/05/03 23:58:32 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 3beb655702434b0d9d230e97a6140e64. Failed operations: [MlflowException(\"API request to http://mlflow-starter-server:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'mlflow-starter-server\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n",
      "2023/05/03 23:59:33 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 3beb655702434b0d9d230e97a6140e64. Failed operations: [MlflowException(\"API request to http://mlflow-starter-server:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'mlflow-starter-server\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n",
      "2023/05/04 00:00:33 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during sklearn autologging: The following failures occurred while performing one or more logging operations: [MlflowException('Failed to perform one or more operations on the run with ID 3beb655702434b0d9d230e97a6140e64. Failed operations: [MlflowException(\"API request to http://mlflow-starter-server:5000/api/2.0/mlflow/runs/log-batch failed with exception HTTPConnectionPool(host=\\'mlflow-starter-server\\', port=5000): Max retries exceeded with url: /api/2.0/mlflow/runs/log-batch (Caused by ResponseError(\\'too many 500 error responses\\'))\")]')]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 19\u001B[0m\n\u001B[1;32m     13\u001B[0m searcher_bayes \u001B[38;5;241m=\u001B[39m BayesSearchCV(estimator\u001B[38;5;241m=\u001B[39mrf,\n\u001B[1;32m     14\u001B[0m                     search_spaces\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m     15\u001B[0m                     n_iter\u001B[38;5;241m=\u001B[39mn_iter,\n\u001B[1;32m     16\u001B[0m                     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m123\u001B[39m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautolog_with_grid_search\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m run:\n\u001B[0;32m---> 19\u001B[0m     \u001B[43msearcher_bayes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mend_run()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:466\u001B[0m, in \u001B[0;36mBayesSearchCV.fit\u001B[0;34m(self, X, y, groups, callback, **fit_params)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs)\n\u001B[0;32m--> 466\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;66;03m# BaseSearchCV never ranked train scores,\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;66;03m# but apparently we used to ship this (back-compat)\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_train_score:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    870\u001B[0m     )\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:512\u001B[0m, in \u001B[0;36mBayesSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n_iter \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# when n_iter < n_points points left for evaluation\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     n_points_adjusted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(n_iter, n_points)\n\u001B[0;32m--> 512\u001B[0m     optim_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43msearch_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_points_adjusted\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    516\u001B[0m     n_iter \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m n_points\n\u001B[1;32m    518\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:408\u001B[0m, in \u001B[0;36mBayesSearchCV._step\u001B[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# make lists into dictionaries\u001B[39;00m\n\u001B[1;32m    406\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m [point_asdict(search_space, p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params]\n\u001B[0;32m--> 408\u001B[0m all_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[38;5;66;03m# Feed the point and objective value back into optimizer\u001B[39;00m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001B[39;00m\n\u001B[1;32m    411\u001B[0m local_results \u001B[38;5;241m=\u001B[39m all_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(params):]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    818\u001B[0m         )\n\u001B[1;32m    819\u001B[0m     )\n\u001B[0;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[1;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 686\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:554\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    552\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 554\u001B[0m     \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    558\u001B[0m try_log_autologging_event(\n\u001B[1;32m    559\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n\u001B[1;32m    560\u001B[0m     session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    564\u001B[0m     kwargs,\n\u001B[1;32m    565\u001B[0m )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:254\u001B[0m, in \u001B[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n\u001B[1;32m    251\u001B[0m     managed_run \u001B[38;5;241m=\u001B[39m create_managed_run()\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 254\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001B[39;00m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001B[39;00m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m managed_run:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1580\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_fit\u001B[0;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mshould_log():\n\u001B[1;32m   1577\u001B[0m     \u001B[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001B[39;00m\n\u001B[1;32m   1578\u001B[0m     \u001B[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001B[39;00m\n\u001B[1;32m   1579\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n\u001B[0;32m-> 1580\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfit_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1581\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_log_post_training_metrics:\n\u001B[1;32m   1582\u001B[0m         _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mregister_model(\n\u001B[1;32m   1583\u001B[0m             \u001B[38;5;28mself\u001B[39m, mlflow\u001B[38;5;241m.\u001B[39mactive_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m   1584\u001B[0m         )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1371\u001B[0m, in \u001B[0;36m_autolog.<locals>.fit_mlflow\u001B[0;34m(original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1369\u001B[0m _log_posttraining_metadata(autologging_client, \u001B[38;5;28mself\u001B[39m, X, y_true, sample_weight)\n\u001B[1;32m   1370\u001B[0m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m-> 1371\u001B[0m \u001B[43mparams_logging_future\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mawait_completion\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1372\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m fit_output\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/autologging_utils/client.py:64\u001B[0m, in \u001B[0;36mRunOperations.await_completion\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m future \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_operation_futures:\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 64\u001B[0m         \u001B[43mfuture\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresult\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     66\u001B[0m         failed_operations\u001B[38;5;241m.\u001B[39mappend(e)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/concurrent/futures/_base.py:453\u001B[0m, in \u001B[0;36mFuture.result\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    450\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;241m==\u001B[39m FINISHED:\n\u001B[1;32m    451\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__get_result()\n\u001B[0;32m--> 453\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_condition\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_state \u001B[38;5;129;01min\u001B[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CancelledError()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/threading.py:320\u001B[0m, in \u001B[0;36mCondition.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    318\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:    \u001B[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001B[39;00m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 320\u001B[0m         \u001B[43mwaiter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43macquire\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    321\u001B[0m         gotit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    322\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Bayesian\n",
    "n_iter = 5\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "    }\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "searcher_bayes = BayesSearchCV(estimator=rf,\n",
    "                    search_spaces=params,\n",
    "                    n_iter=n_iter,\n",
    "                    random_state=123)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_grid_search\") as run:\n",
    "    searcher_bayes.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:01:36.623795Z",
     "start_time": "2023-05-04T00:01:36.619588Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:06.418051Z",
     "start_time": "2023-05-04T00:01:49.854212Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 00:01:50 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/05/04 00:02:05 INFO mlflow.sklearn.utils: Logging the 5 best runs, 22 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_with_autolog\")\n",
    "\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "searcher = GridSearchCV(estimator=rf, param_grid=params)\n",
    "\n",
    "with mlflow.start_run(run_name=\"run_3\") as run:\n",
    "    searcher.fit(X_train, y_train)\n",
    "mlflow.end_run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute a model stored as an artifact inside a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:09.452843Z",
     "start_time": "2023-05-04T00:02:06.875337Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 00:02:07 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_to_predict\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, max_features=10)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the UI or the API to get the relevant information for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:10.874170Z",
     "start_time": "2023-05-04T00:02:10.745657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: runs:/5278c8b0350c44ee83d5bfb19c520f77/model\n",
      "Showing predictions\n",
      "[0.   0.   1.   1.02 0.99 0.   1.98 0.01 0.   1.83 2.   0.05 0.01 0.\n",
      " 0.05 0.   0.   1.88 1.55 0.99 0.   1.13 0.99 1.66 1.11 1.98 1.88 0.04\n",
      " 0.99 2.   0.01 1.   0.01 1.9  0.23 0.   1.02 0.04 1.   0.01 1.   0.17\n",
      " 0.86 1.17 1.02]\n"
     ]
    }
   ],
   "source": [
    "# get model path from run id \n",
    "\n",
    "model_path = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# load using sklearn flavor\n",
    "loaded_model = mlflow.sklearn.load_model(model_path)\n",
    "\n",
    "print(\"Showing predictions\")\n",
    "print(loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the frameork where we are going to use our model is not scikit, e.g. could be PyTorch or Tensorflow. We can call the model using an abstract function, so that if you now change the flavour of your model, you don't need to use any if statement or change the method of your class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:12.584114Z",
     "start_time": "2023-05-04T00:02:12.434130Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: runs:/5278c8b0350c44ee83d5bfb19c520f77/model\n",
      "Showing predictions\n",
      "[0.   0.   1.   1.02 0.99 0.   1.98 0.01 0.   1.83 2.   0.05 0.01 0.\n",
      " 0.05 0.   0.   1.88 1.55 0.99 0.   1.13 0.99 1.66 1.11 1.98 1.88 0.04\n",
      " 0.99 2.   0.01 1.   0.01 1.9  0.23 0.   1.02 0.04 1.   0.01 1.   0.17\n",
      " 0.86 1.17 1.02]\n"
     ]
    }
   ],
   "source": [
    "# get model path from run id \n",
    "\n",
    "model_path = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# load using abstract flavor\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "print(\"Showing predictions\")\n",
    "print(loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if you want to use an unsupported framework or any different logic of prediction? \n",
    "\n",
    "We can creat a custom model by extending mlflow.pyfunc.PythonModel, with 2 methods: load_context (responsible for loading the ML artifacts) and predict. \n",
    "\n",
    "I am going to use one example from MLFlow community the VADER sentiment analysis (ADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:38.049051Z",
     "start_time": "2023-05-04T00:02:36.219304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/04 00:02:36 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# create an MLflow-compliant model by extending PythonModel\n",
    "class TextAnalyzerModel(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        pass\n",
    "\n",
    "    def _score(self, txt):\n",
    "        prediction_scores = self._analyser.polarity_scores(txt)\n",
    "        return prediction_scores\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        model_output = model_input.apply(lambda col: self._score(col))\n",
    "        return model_output\n",
    "\n",
    "# connect to mlflow and set experiment\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"sentiment_analysis\")\n",
    "\n",
    "# enable autolog\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "model_artifact_path = \"vader_model\"\n",
    "model = TextAnalyzerModel()\n",
    "\n",
    "# execute run\n",
    "with mlflow.start_run(run_name=\"Vader Sentiment Analysis\") as run:\n",
    "    mlflow.log_param(\"algorithm\", \"VADER\")\n",
    "    mlflow.pyfunc.log_model(artifact_path=model_artifact_path, \n",
    "                          python_model=model)\n",
    "    run_id = run.info.run_id\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the the new experiment and run, we can load the model and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:17.129128Z",
     "start_time": "2023-05-04T00:02:17.066079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<This is a bad class. I hate MLOps and the professor! :-C. But our campus is good.> -- {'neg': 0.215, 'neu': 0.616, 'pos': 0.169, 'compound': 0.1386}\n",
      "<Lovely weather during the weekend.> -- {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.5859}\n",
      "<LOL, this guy fell off a chair while listening the professor.> -- {'neg': 0.0, 'neu': 0.739, 'pos': 0.261, 'compound': 0.5473}\n",
      "<This is INSANE! How can you do such TERRIBLE thing?????> -- {'neg': 0.516, 'neu': 0.484, 'pos': 0.0, 'compound': -0.8597}\n"
     ]
    }
   ],
   "source": [
    "model_uri = f\"runs:/{run_id}/vader_model\"\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "queries = [\"This is a bad class. I hate MLOps and the professor! :-C. But our campus is good.\",\n",
    "           \"Lovely weather during the weekend.\",\n",
    "           \"LOL, this guy fell off a chair while listening the professor.\",\n",
    "           \"This is INSANE! How can you do such TERRIBLE thing?????\"]\n",
    "\n",
    "for q in queries:\n",
    "    m_input = pd.DataFrame([q])\n",
    "    scores = loaded_model.predict(m_input)\n",
    "    print(f\"<{q}> -- {str(scores[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step: let's registry our model. Why ? If you keep evolving a model, you’ll need to know which version is in production. You have to implement here the logic of champion and challenger, tested model, ready for deploy, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:23.217321Z",
     "start_time": "2023-05-04T00:02:18.680462Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Successfully registered model 'my_registered_model_1'.\n",
      "2023/05/04 00:02:23 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: my_registered_model_1, version 1\n",
      "Created version '1' of model 'my_registered_model_1'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"log_and_register\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=rf,\n",
    "    artifact_path=\"sklearn-model\",\n",
    "    registered_model_name=\"my_registered_model_1\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this version of the model, directly from the model registry, you only need to change the path, i.e. change the source from runs to models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:23.256890Z",
     "start_time": "2023-05-04T00:02:23.218809Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_version = 1\n",
    "model_path = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:23.290903Z",
     "start_time": "2023-05-04T00:02:23.282038Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing predictions\n",
      "[0.01       0.01333333 0.98       1.01       1.01       0.07\n",
      " 1.98       0.15       0.01       1.74       2.         0.06666667\n",
      " 0.19       0.08333333 0.28       0.08333333 0.23333333 1.9\n",
      " 1.83       1.03       0.05       1.33       0.99       1.45\n",
      " 1.26       1.85       1.92       0.16333333 1.05       1.94\n",
      " 0.         0.99       0.09       1.86       0.29666667 0.07\n",
      " 1.09       0.05       1.         0.02       1.04       0.33333333\n",
      " 0.55       1.1        1.07      ]\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing predictions\")\n",
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly distinguish the version of the model: \n",
    "- which is in production (Production); \n",
    "- which is being tested (Staging); \n",
    "- which has been decommissioned (Archived);\n",
    "- which has just been generated (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:02:49.729630Z",
     "start_time": "2023-05-04T00:02:49.552431Z"
    }
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "No versions of model with name 'my_registered_model_1' and stage 'production' found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[30], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmy_registered_model_1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/production\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:577\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\n\u001B[1;32m    550\u001B[0m     model_uri: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    551\u001B[0m     suppress_warnings: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    552\u001B[0m     dst_path: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    553\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PyFuncModel:\n\u001B[1;32m    554\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;124;03m    Load a model stored in Python function format.\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    575\u001B[0m \u001B[38;5;124;03m                     path will be created.\u001B[39;00m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m     local_path \u001B[38;5;241m=\u001B[39m \u001B[43m_download_artifact_from_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdst_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m suppress_warnings:\n\u001B[1;32m    580\u001B[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m                    a local output path will be created.\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_uri\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[1;32m    101\u001B[0m     artifact_path\u001B[38;5;241m=\u001B[39martifact_path, dst_path\u001B[38;5;241m=\u001B[39moutput_path\n\u001B[1;32m    102\u001B[0m )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:106\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[0;34m(artifact_uri)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri):\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m             requirements.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_artifact_repository_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     69\u001B[0m             artifact_uri, \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     )\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrepository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:44\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m DatabricksModelsArtifactRepository(artifact_uri)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 44\u001B[0m     uri \u001B[38;5;241m=\u001B[39m \u001B[43mModelsArtifactRepository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_underlying_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m get_artifact_repository(uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:78\u001B[0m, in \u001B[0;36mModelsArtifactRepository.get_underlying_uri\u001B[0;34m(uri)\u001B[0m\n\u001B[1;32m     74\u001B[0m databricks_profile_uri \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     75\u001B[0m     get_databricks_profile_uri_from_artifact_uri(uri) \u001B[38;5;129;01mor\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n\u001B[1;32m     76\u001B[0m )\n\u001B[1;32m     77\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient(registry_uri\u001B[38;5;241m=\u001B[39mdatabricks_profile_uri)\n\u001B[0;32m---> 78\u001B[0m (name, version) \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_name_and_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m download_uri \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_download_uri(name, version)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:94\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\u001B[38;5;241m.\u001B[39mversion\n\u001B[0;32m---> 94\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(\u001B[43m_get_latest_model_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_stage\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:35\u001B[0m, in \u001B[0;36m_get_latest_model_version\u001B[0;34m(client, name, stage)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(latest) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     34\u001B[0m     stage_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m stage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and stage \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo versions of model with name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mint\u001B[39m(x\u001B[38;5;241m.\u001B[39mversion) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m latest)\n",
      "\u001B[0;31mMlflowException\u001B[0m: No versions of model with name 'my_registered_model_1' and stage 'production' found"
     ]
    }
   ],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_path = f\"models:/{model_name}/production\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-04T00:03:19.676514Z",
     "start_time": "2023-05-04T00:03:19.498674Z"
    }
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "No versions of model with name 'my_registered_model_1' and stage 'staging' found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[31], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmy_registered_model_1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/staging\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:577\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\n\u001B[1;32m    550\u001B[0m     model_uri: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    551\u001B[0m     suppress_warnings: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    552\u001B[0m     dst_path: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    553\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PyFuncModel:\n\u001B[1;32m    554\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;124;03m    Load a model stored in Python function format.\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    575\u001B[0m \u001B[38;5;124;03m                     path will be created.\u001B[39;00m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m     local_path \u001B[38;5;241m=\u001B[39m \u001B[43m_download_artifact_from_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdst_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m suppress_warnings:\n\u001B[1;32m    580\u001B[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m                    a local output path will be created.\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_uri\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[1;32m    101\u001B[0m     artifact_path\u001B[38;5;241m=\u001B[39martifact_path, dst_path\u001B[38;5;241m=\u001B[39moutput_path\n\u001B[1;32m    102\u001B[0m )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:106\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[0;34m(artifact_uri)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri):\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m             requirements.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_artifact_repository_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     69\u001B[0m             artifact_uri, \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     )\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrepository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:44\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m DatabricksModelsArtifactRepository(artifact_uri)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 44\u001B[0m     uri \u001B[38;5;241m=\u001B[39m \u001B[43mModelsArtifactRepository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_underlying_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m get_artifact_repository(uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:78\u001B[0m, in \u001B[0;36mModelsArtifactRepository.get_underlying_uri\u001B[0;34m(uri)\u001B[0m\n\u001B[1;32m     74\u001B[0m databricks_profile_uri \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     75\u001B[0m     get_databricks_profile_uri_from_artifact_uri(uri) \u001B[38;5;129;01mor\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n\u001B[1;32m     76\u001B[0m )\n\u001B[1;32m     77\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient(registry_uri\u001B[38;5;241m=\u001B[39mdatabricks_profile_uri)\n\u001B[0;32m---> 78\u001B[0m (name, version) \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_name_and_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m download_uri \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_download_uri(name, version)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:94\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\u001B[38;5;241m.\u001B[39mversion\n\u001B[0;32m---> 94\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(\u001B[43m_get_latest_model_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_stage\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:35\u001B[0m, in \u001B[0;36m_get_latest_model_version\u001B[0;34m(client, name, stage)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(latest) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     34\u001B[0m     stage_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m stage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and stage \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo versions of model with name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mint\u001B[39m(x\u001B[38;5;241m.\u001B[39mversion) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m latest)\n",
      "\u001B[0;31mMlflowException\u001B[0m: No versions of model with name 'my_registered_model_1' and stage 'staging' found"
     ]
    }
   ],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_path = f\"models:/{model_name}/staging\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

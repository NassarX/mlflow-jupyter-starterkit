{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "import mlflow.sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, explained_variance_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:47.726552Z",
     "start_time": "2023-05-06T04:48:47.104842Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                       Version\r\n",
      "----------------------------- -----------\r\n",
      "aiofiles                      22.1.0\r\n",
      "aiosqlite                     0.19.0\r\n",
      "alembic                       1.10.4\r\n",
      "altair                        4.2.2\r\n",
      "anyio                         3.6.2\r\n",
      "argon2-cffi                   21.3.0\r\n",
      "argon2-cffi-bindings          21.2.0\r\n",
      "asttokens                     2.2.1\r\n",
      "async-generator               1.10\r\n",
      "attrs                         22.2.0\r\n",
      "Babel                         2.12.1\r\n",
      "backcall                      0.2.0\r\n",
      "backports.functools-lru-cache 1.6.4\r\n",
      "beautifulsoup4                4.12.2\r\n",
      "bleach                        6.0.0\r\n",
      "blinker                       1.6.2\r\n",
      "bokeh                         3.1.0\r\n",
      "boltons                       23.0.0\r\n",
      "Bottleneck                    1.3.7\r\n",
      "brotlipy                      0.7.0\r\n",
      "cached-property               1.5.2\r\n",
      "certifi                       2022.12.7\r\n",
      "certipy                       0.1.3\r\n",
      "cffi                          1.15.1\r\n",
      "charset-normalizer            3.1.0\r\n",
      "click                         8.1.3\r\n",
      "cloudpickle                   2.2.1\r\n",
      "colorama                      0.4.6\r\n",
      "comm                          0.1.3\r\n",
      "conda                         23.3.1\r\n",
      "conda-package-handling        2.0.2\r\n",
      "conda_package_streaming       0.7.0\r\n",
      "contourpy                     1.0.7\r\n",
      "cryptography                  40.0.2\r\n",
      "cycler                        0.11.0\r\n",
      "Cython                        0.29.34\r\n",
      "cytoolz                       0.12.0\r\n",
      "dask                          2023.4.1\r\n",
      "databricks-cli                0.17.6\r\n",
      "debugpy                       1.6.7\r\n",
      "decorator                     5.1.1\r\n",
      "defusedxml                    0.7.1\r\n",
      "dill                          0.3.6\r\n",
      "distributed                   2023.4.1\r\n",
      "docker                        6.0.1\r\n",
      "entrypoints                   0.4\r\n",
      "et-xmlfile                    1.1.0\r\n",
      "executing                     1.2.0\r\n",
      "fastjsonschema                2.16.3\r\n",
      "filelock                      3.12.0\r\n",
      "Flask                         2.3.2\r\n",
      "flit_core                     3.8.0\r\n",
      "fonttools                     4.39.3\r\n",
      "fsspec                        2023.4.0\r\n",
      "gitdb                         4.0.10\r\n",
      "GitPython                     3.1.31\r\n",
      "gmpy2                         2.1.2\r\n",
      "greenlet                      2.0.2\r\n",
      "gunicorn                      20.1.0\r\n",
      "h5py                          3.8.0\r\n",
      "idna                          3.4\r\n",
      "imagecodecs                   2023.1.23\r\n",
      "imageio                       2.28.0\r\n",
      "importlib-metadata            6.6.0\r\n",
      "importlib-resources           5.12.0\r\n",
      "ipykernel                     6.22.0\r\n",
      "ipympl                        0.9.3\r\n",
      "ipython                       8.13.1\r\n",
      "ipython-genutils              0.2.0\r\n",
      "ipywidgets                    8.0.6\r\n",
      "itsdangerous                  2.1.2\r\n",
      "jedi                          0.18.2\r\n",
      "Jinja2                        3.1.2\r\n",
      "joblib                        1.2.0\r\n",
      "json5                         0.9.5\r\n",
      "jsonpatch                     1.32\r\n",
      "jsonpointer                   2.0\r\n",
      "jsonschema                    4.17.3\r\n",
      "jupyter_client                8.2.0\r\n",
      "jupyter_core                  5.3.0\r\n",
      "jupyter-events                0.6.3\r\n",
      "jupyter_server                2.5.0\r\n",
      "jupyter_server_fileid         0.9.0\r\n",
      "jupyter-server-mathjax        0.2.6\r\n",
      "jupyter_server_terminals      0.4.4\r\n",
      "jupyter_server_ydoc           0.8.0\r\n",
      "jupyter-telemetry             0.1.0\r\n",
      "jupyter-ydoc                  0.2.3\r\n",
      "jupyterhub                    4.0.0\r\n",
      "jupyterlab                    3.6.3\r\n",
      "jupyterlab-git                0.41.0\r\n",
      "jupyterlab-pygments           0.2.2\r\n",
      "jupyterlab_server             2.22.1\r\n",
      "jupyterlab-widgets            3.0.7\r\n",
      "kiwisolver                    1.4.4\r\n",
      "lazy_loader                   0.2\r\n",
      "libmambapy                    1.4.2\r\n",
      "llvmlite                      0.39.1\r\n",
      "locket                        1.0.0\r\n",
      "lz4                           4.3.2\r\n",
      "Mako                          1.2.4\r\n",
      "mamba                         1.4.2\r\n",
      "Markdown                      3.4.3\r\n",
      "MarkupSafe                    2.1.2\r\n",
      "matplotlib                    3.7.1\r\n",
      "matplotlib-inline             0.1.6\r\n",
      "mistune                       2.0.5\r\n",
      "mlflow                        2.3.1\r\n",
      "mpmath                        1.3.0\r\n",
      "msgpack                       1.0.5\r\n",
      "munkres                       1.1.4\r\n",
      "nbclassic                     0.5.6\r\n",
      "nbclient                      0.7.4\r\n",
      "nbconvert                     7.3.1\r\n",
      "nbdime                        3.2.1\r\n",
      "nbformat                      5.8.0\r\n",
      "nest-asyncio                  1.5.6\r\n",
      "networkx                      3.1\r\n",
      "nltk                          3.5\r\n",
      "notebook                      6.5.4\r\n",
      "notebook_shim                 0.2.3\r\n",
      "numba                         0.56.4\r\n",
      "numexpr                       2.8.4\r\n",
      "numpy                         1.23.5\r\n",
      "oauthlib                      3.2.2\r\n",
      "openpyxl                      3.1.2\r\n",
      "packaging                     23.1\r\n",
      "pamela                        1.0.0\r\n",
      "pandas                        2.0.1\r\n",
      "pandocfilters                 1.5.0\r\n",
      "parso                         0.8.3\r\n",
      "partd                         1.4.0\r\n",
      "patsy                         0.5.3\r\n",
      "pexpect                       4.8.0\r\n",
      "pickleshare                   0.7.5\r\n",
      "Pillow                        9.5.0\r\n",
      "pip                           23.1.2\r\n",
      "pkgutil_resolve_name          1.3.10\r\n",
      "platformdirs                  3.5.0\r\n",
      "pluggy                        1.0.0\r\n",
      "pooch                         1.7.0\r\n",
      "prometheus-client             0.16.0\r\n",
      "prompt-toolkit                3.0.38\r\n",
      "protobuf                      4.21.12\r\n",
      "psutil                        5.9.5\r\n",
      "ptyprocess                    0.7.0\r\n",
      "pure-eval                     0.2.2\r\n",
      "py-cpuinfo                    9.0.0\r\n",
      "pyaml                         21.10.1\r\n",
      "pyarrow                       11.0.0\r\n",
      "pycosat                       0.6.4\r\n",
      "pycparser                     2.21\r\n",
      "pycurl                        7.45.1\r\n",
      "Pygments                      2.15.1\r\n",
      "PyJWT                         2.6.0\r\n",
      "pyOpenSSL                     23.1.1\r\n",
      "pyparsing                     3.0.9\r\n",
      "pyrsistent                    0.19.3\r\n",
      "PySocks                       1.7.1\r\n",
      "python-dateutil               2.8.2\r\n",
      "python-json-logger            2.0.7\r\n",
      "pytz                          2023.3\r\n",
      "PyWavelets                    1.4.1\r\n",
      "PyYAML                        6.0\r\n",
      "pyzmq                         25.0.2\r\n",
      "querystring-parser            1.2.4\r\n",
      "regex                         2023.5.5\r\n",
      "requests                      2.29.0\r\n",
      "rfc3339-validator             0.1.4\r\n",
      "rfc3986-validator             0.1.1\r\n",
      "ruamel.yaml                   0.17.21\r\n",
      "ruamel.yaml.clib              0.2.7\r\n",
      "scikit-image                  0.20.0\r\n",
      "scikit-learn                  1.2.2\r\n",
      "scikit-optimize               0.9.0\r\n",
      "scipy                         1.10.1\r\n",
      "seaborn                       0.12.2\r\n",
      "Send2Trash                    1.8.2\r\n",
      "setuptools                    67.7.2\r\n",
      "six                           1.16.0\r\n",
      "smmap                         3.0.5\r\n",
      "sniffio                       1.3.0\r\n",
      "sortedcontainers              2.4.0\r\n",
      "soupsieve                     2.3.2.post1\r\n",
      "SQLAlchemy                    2.0.11\r\n",
      "sqlparse                      0.4.4\r\n",
      "stack-data                    0.6.2\r\n",
      "statsmodels                   0.13.5\r\n",
      "sympy                         1.11.1\r\n",
      "tables                        3.8.0\r\n",
      "tabulate                      0.9.0\r\n",
      "tblib                         1.7.0\r\n",
      "terminado                     0.17.1\r\n",
      "threadpoolctl                 3.1.0\r\n",
      "tifffile                      2023.4.12\r\n",
      "tinycss2                      1.2.1\r\n",
      "tomli                         2.0.1\r\n",
      "toolz                         0.12.0\r\n",
      "torch                         2.0.0\r\n",
      "tornado                       6.3\r\n",
      "tqdm                          4.56.0\r\n",
      "traitlets                     5.9.0\r\n",
      "typing_extensions             4.5.0\r\n",
      "tzdata                        2023.3\r\n",
      "unicodedata2                  15.0.0\r\n",
      "urllib3                       1.26.15\r\n",
      "vaderSentiment                3.3.2\r\n",
      "wcwidth                       0.2.6\r\n",
      "webencodings                  0.5.1\r\n",
      "websocket-client              1.5.1\r\n",
      "Werkzeug                      2.3.3\r\n",
      "wheel                         0.40.0\r\n",
      "widgetsnbextension            4.0.7\r\n",
      "xlrd                          2.0.1\r\n",
      "xyzservices                   2023.2.0\r\n",
      "y-py                          0.5.9\r\n",
      "ypy-websocket                 0.8.2\r\n",
      "zict                          3.0.0\r\n",
      "zipp                          3.15.0\r\n",
      "zstandard                     0.19.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:47.733689Z",
     "start_time": "2023-05-06T04:48:47.725825Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(mlflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T11:12:01.681597Z",
     "start_time": "2023-05-03T11:12:00.297070Z"
    }
   },
   "source": [
    "I like to create a virtual environment \n",
    "- python -m venv /path/to/new/virtual/environment\n",
    "- source python /path/to/new/virtual/environment/bin/activate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First simple example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow Tracking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keep track of things like the hyperparameters and the metrics you’ve got. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the tunnel with mlflow command in the command line and specify where you want to save your artifacts\n",
    "if you want also the database add     --backend-store-uri sqlite:///mlflow.db \\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T11:40:38.760748Z",
     "start_time": "2023-05-03T11:40:38.739408Z"
    }
   },
   "source": [
    "mlflow server \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --artifacts-destination /home/nuno/Desktop/NovaIMS/mlflow_project/ml_artifacts\\\n",
    "    --default-artifact-root /home/nuno/Desktop/NovaIMS/mlflow_project/ml_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:48.998971Z",
     "start_time": "2023-05-06T04:48:48.963326Z"
    }
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:49.236411Z",
     "start_time": "2023-05-06T04:48:49.224144Z"
    }
   },
   "outputs": [],
   "source": [
    "# descrition that will be used as metadata\n",
    "description = \"the simplest possible example\"\n",
    "\n",
    "# Mlflow tracking server\n",
    "#mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:50.525970Z",
     "start_time": "2023-05-06T04:48:49.506309Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/06 04:48:49 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_first_example' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Experiment: artifact_location='/home/jovyan/artifacts/1', creation_time=1683348530183, experiment_id='1', last_update_time=1683348530183, lifecycle_stage='active', name='mlflow_first_example', tags={}>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"mlflow_first_example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:50.982056Z",
     "start_time": "2023-05-06T04:48:50.528680Z"
    }
   },
   "outputs": [],
   "source": [
    "# executes the run\n",
    "with mlflow.start_run(run_name=\"tracking experiment_1\", description=description) as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:01.746100Z",
     "start_time": "2023-05-03T18:11:01.027764Z"
    }
   },
   "source": [
    "Runs are grouped into experiments. Each run can contain, for example, a different set of hyperparameters. Also, if you don’t specify an experiment name, the run you’re currently executing will be recorded under the Default experiment, which is created automatically by MLflow for you. Let's change to another name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:51.376220Z",
     "start_time": "2023-05-06T04:48:50.985955Z"
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"mlflow_first_example\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"params_no_artifacts_logged\") as run:\n",
    "\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.8)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:51.727471Z",
     "start_time": "2023-05-06T04:48:51.375315Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"params_no_artifacts_logged\") as run:\n",
    "\n",
    "    params = {\"n_estimators\":120, \"max_depth\":3, \"max_features\":6}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test2\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.9)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag_2\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:52.035681Z",
     "start_time": "2023-05-06T04:48:51.727670Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "\n",
    "    params = {\"n_estimators\":120, \"max_depth\":3, \"max_features\":6}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "    explained_variance = explained_variance_score(y_test, y_pred)\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_param(\"test\", \"test2\")\n",
    "    mlflow.log_metric(\"explained_variance\", explained_variance)\n",
    "    mlflow.log_metric(\"mse\", mse)\n",
    "    mlflow.log_metric(\"my_metric\", 0.9)\n",
    "    mlflow.set_tag(\"tag\", \"this_is_a_tag_2\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:05.221928Z",
     "start_time": "2023-05-03T18:11:04.536224Z"
    }
   },
   "source": [
    "And we can save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:54.427999Z",
     "start_time": "2023-05-06T04:48:52.287723Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"real_model_to_save\") as run:\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "\n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=rf,\n",
    "    artifact_path=\"real_model_to_save\",\n",
    "  )\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:11:09.429731Z",
     "start_time": "2023-05-03T18:11:06.168881Z"
    }
   },
   "source": [
    "You now have not only your trained model managed for you (the model.pkl file), but you also have it’s dependencies automatically captured in three different flavours, i.e. conda.yaml, python_env.yaml and requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also log an input example alongside the artifacts so that, for example, anyone could test a deployment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:58.162422Z",
     "start_time": "2023-05-06T04:48:58.159391Z"
    }
   },
   "outputs": [],
   "source": [
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:58.600616Z",
     "start_time": "2023-05-06T04:48:58.586636Z"
    }
   },
   "outputs": [],
   "source": [
    "signature = infer_signature(X_train, rf.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-06T04:48:59.271653Z",
     "start_time": "2023-05-06T04:48:59.263906Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:49:02.086003Z",
     "start_time": "2023-05-06T04:49:00.037456Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"artifact_run_sign\") as run:\n",
    "    params = {\"n_estimators\":100, \"max_depth\":6, \"max_features\":3}\n",
    "    \n",
    "    rf = RandomForestRegressor(**params)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    signature = infer_signature(X_train, rf.predict(X_test))\n",
    "    input_example = X_train[0]\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.sklearn.log_model(\n",
    "        sk_model=rf,\n",
    "        artifact_path=\"random_forest_regressor\",\n",
    "        input_example=input_example,\n",
    "        signature=signature\n",
    "  )\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-03T18:01:34.166519Z",
     "start_time": "2023-05-03T18:01:31.343774Z"
    }
   },
   "source": [
    "Instead of explicitily giving the arguments for mlflow log, there is a nice function to the autolog:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:49:05.067114Z",
     "start_time": "2023-05-06T04:49:02.089526Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/06 04:49:02 INFO mlflow.tracking.fluent: Experiment with name 'mlflow_tracking_with_autolog' does not exist. Creating a new experiment.\n",
      "2023/05/06 04:49:02 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/05/06 04:49:02 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '97fed6480a1f4feda5d4fe3357a17c38', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current sklearn workflow\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_with_autolog\")\n",
    "\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "# train the model\n",
    "rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "with mlflow.start_run(run_name=\"run_2\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-05-03T18:01:34.166270Z"
    }
   },
   "source": [
    "Librarires that support autologging:\n",
    "\n",
    "- Scikit-learn\n",
    "\n",
    "- Keras\n",
    "\n",
    "- Gluon\n",
    "\n",
    "- XGBoost\n",
    "\n",
    "- LightGBM\n",
    "\n",
    "- Statsmodels\n",
    "\n",
    "- Spark\n",
    "\n",
    "- Fastai\n",
    "\n",
    "- Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to test different parameters, we can use a nested run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:17:02.065457Z",
     "start_time": "2023-05-06T04:16:57.223715Z"
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"main_run_for_nested\") as run:\n",
    "    for estimators in range(20, 100, 20):\n",
    "        with mlflow.start_run(run_name=f\"nested_{estimators}_estimators\", nested=True) as nested:\n",
    "            rf = RandomForestRegressor(n_estimators=estimators, max_depth=6, max_features=3)\n",
    "            rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improving our code with  hyperparameter fine-tunning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-04T22:34:57.280212Z",
     "start_time": "2023-05-04T22:34:53.415913Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[17], line 19\u001B[0m\n\u001B[1;32m     13\u001B[0m searcher_bayes \u001B[38;5;241m=\u001B[39m BayesSearchCV(estimator\u001B[38;5;241m=\u001B[39mrf,\n\u001B[1;32m     14\u001B[0m                     search_spaces\u001B[38;5;241m=\u001B[39mparams,\n\u001B[1;32m     15\u001B[0m                     n_iter\u001B[38;5;241m=\u001B[39mn_iter,\n\u001B[1;32m     16\u001B[0m                     random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m123\u001B[39m)\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mstart_run(run_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mautolog_with_grid_search\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m run:\n\u001B[0;32m---> 19\u001B[0m     \u001B[43msearcher_bayes\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     20\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mend_run()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:466\u001B[0m, in \u001B[0;36mBayesSearchCV.fit\u001B[0;34m(self, X, y, groups, callback, **fit_params)\u001B[0m\n\u001B[1;32m    463\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    464\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer_kwargs)\n\u001B[0;32m--> 466\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgroups\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    468\u001B[0m \u001B[38;5;66;03m# BaseSearchCV never ranked train scores,\u001B[39;00m\n\u001B[1;32m    469\u001B[0m \u001B[38;5;66;03m# but apparently we used to ship this (back-compat)\u001B[39;00m\n\u001B[1;32m    470\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreturn_train_score:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001B[0m, in \u001B[0;36mBaseSearchCV.fit\u001B[0;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[1;32m    868\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_format_results(\n\u001B[1;32m    869\u001B[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001B[1;32m    870\u001B[0m     )\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results\n\u001B[0;32m--> 874\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[38;5;66;03m# multimetric is determined here because in the case of a callable\u001B[39;00m\n\u001B[1;32m    877\u001B[0m \u001B[38;5;66;03m# self.scoring the return type is only known after calling\u001B[39;00m\n\u001B[1;32m    878\u001B[0m first_test_score \u001B[38;5;241m=\u001B[39m all_out[\u001B[38;5;241m0\u001B[39m][\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtest_scores\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:512\u001B[0m, in \u001B[0;36mBayesSearchCV._run_search\u001B[0;34m(self, evaluate_candidates)\u001B[0m\n\u001B[1;32m    508\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m n_iter \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;66;03m# when n_iter < n_points points left for evaluation\u001B[39;00m\n\u001B[1;32m    510\u001B[0m     n_points_adjusted \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmin\u001B[39m(n_iter, n_points)\n\u001B[0;32m--> 512\u001B[0m     optim_result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    513\u001B[0m \u001B[43m        \u001B[49m\u001B[43msearch_space\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    514\u001B[0m \u001B[43m        \u001B[49m\u001B[43mevaluate_candidates\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_points\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_points_adjusted\u001B[49m\n\u001B[1;32m    515\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    516\u001B[0m     n_iter \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m=\u001B[39m n_points\n\u001B[1;32m    518\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m eval_callbacks(callbacks, optim_result):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/skopt/searchcv.py:408\u001B[0m, in \u001B[0;36mBayesSearchCV._step\u001B[0;34m(self, search_space, optimizer, evaluate_candidates, n_points)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;66;03m# make lists into dictionaries\u001B[39;00m\n\u001B[1;32m    406\u001B[0m params_dict \u001B[38;5;241m=\u001B[39m [point_asdict(search_space, p) \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m params]\n\u001B[0;32m--> 408\u001B[0m all_results \u001B[38;5;241m=\u001B[39m \u001B[43mevaluate_candidates\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams_dict\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    409\u001B[0m \u001B[38;5;66;03m# Feed the point and objective value back into optimizer\u001B[39;00m\n\u001B[1;32m    410\u001B[0m \u001B[38;5;66;03m# Optimizer minimizes objective, hence provide negative score\u001B[39;00m\n\u001B[1;32m    411\u001B[0m local_results \u001B[38;5;241m=\u001B[39m all_results[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmean_test_score\u001B[39m\u001B[38;5;124m\"\u001B[39m][\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(params):]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001B[0m, in \u001B[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001B[0;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[1;32m    813\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    814\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting \u001B[39m\u001B[38;5;132;01m{0}\u001B[39;00m\u001B[38;5;124m folds for each of \u001B[39m\u001B[38;5;132;01m{1}\u001B[39;00m\u001B[38;5;124m candidates,\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    816\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m totalling \u001B[39m\u001B[38;5;132;01m{2}\u001B[39;00m\u001B[38;5;124m fits\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m    817\u001B[0m             n_splits, n_candidates, n_candidates \u001B[38;5;241m*\u001B[39m n_splits\n\u001B[1;32m    818\u001B[0m         )\n\u001B[1;32m    819\u001B[0m     )\n\u001B[0;32m--> 821\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mparallel\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    822\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdelayed\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_fit_and_score\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    823\u001B[0m \u001B[43m        \u001B[49m\u001B[43mclone\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbase_estimator\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    825\u001B[0m \u001B[43m        \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    826\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    827\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtest\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    828\u001B[0m \u001B[43m        \u001B[49m\u001B[43mparameters\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparameters\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    829\u001B[0m \u001B[43m        \u001B[49m\u001B[43msplit_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_splits\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    830\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcandidate_progress\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_candidates\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    831\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_and_score_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    832\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mcand_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparameters\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43msplit_idx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mproduct\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    834\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcandidate_params\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msplit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgroups\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    835\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    836\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    838\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(out) \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    839\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    840\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo fits were performed. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    841\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWas the CV iterator empty? \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    842\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mWere there no candidates?\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    843\u001B[0m     )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m     58\u001B[0m config \u001B[38;5;241m=\u001B[39m get_config()\n\u001B[1;32m     59\u001B[0m iterable_with_config \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     60\u001B[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001B[1;32m     61\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m delayed_func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m iterable\n\u001B[1;32m     62\u001B[0m )\n\u001B[0;32m---> 63\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43miterable_with_config\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:1088\u001B[0m, in \u001B[0;36mParallel.__call__\u001B[0;34m(self, iterable)\u001B[0m\n\u001B[1;32m   1085\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdispatch_one_batch(iterator):\n\u001B[1;32m   1086\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_iterating \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_original_iterator \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1088\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdispatch_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m   1089\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m   1091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m pre_dispatch \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mall\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m n_jobs \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   1092\u001B[0m     \u001B[38;5;66;03m# The iterable was consumed all at once by the above for loop.\u001B[39;00m\n\u001B[1;32m   1093\u001B[0m     \u001B[38;5;66;03m# No need to wait for async callbacks to trigger to\u001B[39;00m\n\u001B[1;32m   1094\u001B[0m     \u001B[38;5;66;03m# consumption.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:901\u001B[0m, in \u001B[0;36mParallel.dispatch_one_batch\u001B[0;34m(self, iterator)\u001B[0m\n\u001B[1;32m    899\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    900\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 901\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dispatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtasks\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    902\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:819\u001B[0m, in \u001B[0;36mParallel._dispatch\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m    818\u001B[0m     job_idx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs)\n\u001B[0;32m--> 819\u001B[0m     job \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_backend\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_async\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    820\u001B[0m     \u001B[38;5;66;03m# A job can complete so quickly than its callback is\u001B[39;00m\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;66;03m# called before we get here, causing self._jobs to\u001B[39;00m\n\u001B[1;32m    822\u001B[0m     \u001B[38;5;66;03m# grow. To ensure correct results ordering, .insert is\u001B[39;00m\n\u001B[1;32m    823\u001B[0m     \u001B[38;5;66;03m# used (rather than .append) in the following line\u001B[39;00m\n\u001B[1;32m    824\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jobs\u001B[38;5;241m.\u001B[39minsert(job_idx, job)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:208\u001B[0m, in \u001B[0;36mSequentialBackend.apply_async\u001B[0;34m(self, func, callback)\u001B[0m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_async\u001B[39m(\u001B[38;5;28mself\u001B[39m, func, callback\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    207\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Schedule a func to be run\"\"\"\u001B[39;00m\n\u001B[0;32m--> 208\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mImmediateResult\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    209\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m callback:\n\u001B[1;32m    210\u001B[0m         callback(result)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/_parallel_backends.py:597\u001B[0m, in \u001B[0;36mImmediateResult.__init__\u001B[0;34m(self, batch)\u001B[0m\n\u001B[1;32m    594\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, batch):\n\u001B[1;32m    595\u001B[0m     \u001B[38;5;66;03m# Don't delay the application, to avoid keeping the input\u001B[39;00m\n\u001B[1;32m    596\u001B[0m     \u001B[38;5;66;03m# arguments in memory\u001B[39;00m\n\u001B[0;32m--> 597\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults \u001B[38;5;241m=\u001B[39m \u001B[43mbatch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36mBatchedCalls.__call__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/joblib/parallel.py:288\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    284\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    285\u001B[0m     \u001B[38;5;66;03m# Set the default nested backend to self._backend but do not set the\u001B[39;00m\n\u001B[1;32m    286\u001B[0m     \u001B[38;5;66;03m# change the default number of processes to -1\u001B[39;00m\n\u001B[1;32m    287\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m parallel_backend(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backend, n_jobs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_jobs):\n\u001B[0;32m--> 288\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    289\u001B[0m                 \u001B[38;5;28;01mfor\u001B[39;00m func, args, kwargs \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mitems]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/utils/parallel.py:123\u001B[0m, in \u001B[0;36m_FuncWrapper.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    121\u001B[0m     config \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    122\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mconfig):\n\u001B[0;32m--> 123\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:686\u001B[0m, in \u001B[0;36m_fit_and_score\u001B[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[1;32m    684\u001B[0m         estimator\u001B[38;5;241m.\u001B[39mfit(X_train, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mfit_params)\n\u001B[1;32m    685\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 686\u001B[0m         \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m     \u001B[38;5;66;03m# Note fit time as time until error\u001B[39;00m\n\u001B[1;32m    690\u001B[0m     fit_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime() \u001B[38;5;241m-\u001B[39m start_time\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:554\u001B[0m, in \u001B[0;36msafe_patch.<locals>.safe_patch_function\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    552\u001B[0m     patch_function\u001B[38;5;241m.\u001B[39mcall(call_original, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    553\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 554\u001B[0m     \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcall_original\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    556\u001B[0m session\u001B[38;5;241m.\u001B[39mstate \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msucceeded\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    558\u001B[0m try_log_autologging_event(\n\u001B[1;32m    559\u001B[0m     AutologgingEventLogger\u001B[38;5;241m.\u001B[39mget_logger()\u001B[38;5;241m.\u001B[39mlog_patch_function_success,\n\u001B[1;32m    560\u001B[0m     session,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    564\u001B[0m     kwargs,\n\u001B[1;32m    565\u001B[0m )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:254\u001B[0m, in \u001B[0;36mwith_managed_run.<locals>.patch_with_managed_run\u001B[0;34m(original, *args, **kwargs)\u001B[0m\n\u001B[1;32m    251\u001B[0m     managed_run \u001B[38;5;241m=\u001B[39m create_managed_run()\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 254\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[43mpatch_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mException\u001B[39;00m, \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m):\n\u001B[1;32m    256\u001B[0m     \u001B[38;5;66;03m# In addition to standard Python exceptions, handle keyboard interrupts to ensure\u001B[39;00m\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;66;03m# that runs are terminated if a user prematurely interrupts training execution\u001B[39;00m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;66;03m# (e.g. via sigint / ctrl-c)\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m managed_run:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1580\u001B[0m, in \u001B[0;36m_autolog.<locals>.patched_fit\u001B[0;34m(fit_impl, allow_children_patch, original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1576\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mshould_log():\n\u001B[1;32m   1577\u001B[0m     \u001B[38;5;66;03m# In `fit_mlflow` call, it will also call metric API for computing training metrics\u001B[39;00m\n\u001B[1;32m   1578\u001B[0m     \u001B[38;5;66;03m# so we need temporarily disable the post_training_metrics patching.\u001B[39;00m\n\u001B[1;32m   1579\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mdisable_log_post_training_metrics():\n\u001B[0;32m-> 1580\u001B[0m         result \u001B[38;5;241m=\u001B[39m \u001B[43mfit_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1581\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m should_log_post_training_metrics:\n\u001B[1;32m   1582\u001B[0m         _AUTOLOGGING_METRICS_MANAGER\u001B[38;5;241m.\u001B[39mregister_model(\n\u001B[1;32m   1583\u001B[0m             \u001B[38;5;28mself\u001B[39m, mlflow\u001B[38;5;241m.\u001B[39mactive_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m   1584\u001B[0m         )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1369\u001B[0m, in \u001B[0;36m_autolog.<locals>.fit_mlflow\u001B[0;34m(original, self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1367\u001B[0m params_logging_future \u001B[38;5;241m=\u001B[39m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m   1368\u001B[0m fit_output \u001B[38;5;241m=\u001B[39m original(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m-> 1369\u001B[0m \u001B[43m_log_posttraining_metadata\u001B[49m\u001B[43m(\u001B[49m\u001B[43mautologging_client\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1370\u001B[0m autologging_client\u001B[38;5;241m.\u001B[39mflush(synchronous\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1371\u001B[0m params_logging_future\u001B[38;5;241m.\u001B[39mawait_completion()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1486\u001B[0m, in \u001B[0;36m_autolog.<locals>._log_posttraining_metadata\u001B[0;34m(autologging_client, estimator, X, y, sample_weight)\u001B[0m\n\u001B[1;32m   1476\u001B[0m     input_example, signature \u001B[38;5;241m=\u001B[39m resolve_input_example_and_signature(\n\u001B[1;32m   1477\u001B[0m         get_input_example,\n\u001B[1;32m   1478\u001B[0m         infer_model_signature,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1481\u001B[0m         _logger,\n\u001B[1;32m   1482\u001B[0m     )\n\u001B[1;32m   1483\u001B[0m     registered_model_name \u001B[38;5;241m=\u001B[39m get_autologging_config(\n\u001B[1;32m   1484\u001B[0m         FLAVOR_NAME, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mregistered_model_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1485\u001B[0m     )\n\u001B[0;32m-> 1486\u001B[0m     \u001B[43m_log_model_with_except_handling\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1487\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1488\u001B[0m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmodel\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1489\u001B[0m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1490\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1491\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserialization_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserialization_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1492\u001B[0m \u001B[43m        \u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1493\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1495\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _is_parameter_search_estimator(estimator):\n\u001B[1;32m   1496\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(estimator, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbest_estimator_\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m log_models:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:1470\u001B[0m, in \u001B[0;36m_autolog.<locals>._log_posttraining_metadata.<locals>._log_model_with_except_handling\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1468\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_log_model_with_except_handling\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1469\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1470\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mlog_model\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1471\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m _SklearnCustomModelPicklingError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m   1472\u001B[0m         _logger\u001B[38;5;241m.\u001B[39mwarning(\u001B[38;5;28mstr\u001B[39m(e))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:424\u001B[0m, in \u001B[0;36mlog_model\u001B[0;34m(sk_model, artifact_path, conda_env, code_paths, serialization_format, registered_model_name, signature, input_example, await_registration_for, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001B[0m\n\u001B[1;32m    331\u001B[0m \u001B[38;5;129m@format_docstring\u001B[39m(LOG_MODEL_PARAM_DOCS\u001B[38;5;241m.\u001B[39mformat(package_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mscikit-learn\u001B[39m\u001B[38;5;124m\"\u001B[39m))\n\u001B[1;32m    332\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mlog_model\u001B[39m(\n\u001B[1;32m    333\u001B[0m     sk_model,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    345\u001B[0m     metadata\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    346\u001B[0m ):\n\u001B[1;32m    347\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    348\u001B[0m \u001B[38;5;124;03m    Log a scikit-learn model as an MLflow artifact for the current run. Produces an MLflow Model\u001B[39;00m\n\u001B[1;32m    349\u001B[0m \u001B[38;5;124;03m    containing the following flavors:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    422\u001B[0m \u001B[38;5;124;03m        mlflow.sklearn.log_model(sk_model, \"sk_models\")\u001B[39;00m\n\u001B[1;32m    423\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 424\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mModel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    425\u001B[0m \u001B[43m        \u001B[49m\u001B[43martifact_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43martifact_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    426\u001B[0m \u001B[43m        \u001B[49m\u001B[43mflavor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msklearn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    427\u001B[0m \u001B[43m        \u001B[49m\u001B[43msk_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msk_model\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    428\u001B[0m \u001B[43m        \u001B[49m\u001B[43mconda_env\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mconda_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    429\u001B[0m \u001B[43m        \u001B[49m\u001B[43mcode_paths\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode_paths\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    430\u001B[0m \u001B[43m        \u001B[49m\u001B[43mserialization_format\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mserialization_format\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    431\u001B[0m \u001B[43m        \u001B[49m\u001B[43mregistered_model_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mregistered_model_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    432\u001B[0m \u001B[43m        \u001B[49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    433\u001B[0m \u001B[43m        \u001B[49m\u001B[43minput_example\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_example\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    434\u001B[0m \u001B[43m        \u001B[49m\u001B[43mawait_registration_for\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mawait_registration_for\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    435\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    436\u001B[0m \u001B[43m        \u001B[49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mextra_pip_requirements\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    437\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpyfunc_predict_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    438\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetadata\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetadata\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    439\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/models/model.py:547\u001B[0m, in \u001B[0;36mModel.log\u001B[0;34m(cls, artifact_path, flavor, registered_model_name, await_registration_for, metadata, **kwargs)\u001B[0m\n\u001B[1;32m    545\u001B[0m run_id \u001B[38;5;241m=\u001B[39m mlflow\u001B[38;5;241m.\u001B[39mtracking\u001B[38;5;241m.\u001B[39mfluent\u001B[38;5;241m.\u001B[39m_get_or_start_run()\u001B[38;5;241m.\u001B[39minfo\u001B[38;5;241m.\u001B[39mrun_id\n\u001B[1;32m    546\u001B[0m mlflow_model \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mcls\u001B[39m(artifact_path\u001B[38;5;241m=\u001B[39martifact_path, run_id\u001B[38;5;241m=\u001B[39mrun_id, metadata\u001B[38;5;241m=\u001B[39mmetadata)\n\u001B[0;32m--> 547\u001B[0m \u001B[43mflavor\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mlocal_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmlflow_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmlflow_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    548\u001B[0m mlflow\u001B[38;5;241m.\u001B[39mtracking\u001B[38;5;241m.\u001B[39mfluent\u001B[38;5;241m.\u001B[39mlog_artifacts(local_path, mlflow_model\u001B[38;5;241m.\u001B[39martifact_path)\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/sklearn/__init__.py:302\u001B[0m, in \u001B[0;36msave_model\u001B[0;34m(sk_model, path, conda_env, code_paths, mlflow_model, serialization_format, signature, input_example, pip_requirements, extra_pip_requirements, pyfunc_predict_fn, metadata)\u001B[0m\n\u001B[1;32m    299\u001B[0m     default_reqs \u001B[38;5;241m=\u001B[39m get_default_pip_requirements(include_cloudpickle)\n\u001B[1;32m    300\u001B[0m     \u001B[38;5;66;03m# To ensure `_load_pyfunc` can successfully load the model during the dependency\u001B[39;00m\n\u001B[1;32m    301\u001B[0m     \u001B[38;5;66;03m# inference, `mlflow_model.save` must be called beforehand to save an MLmodel file.\u001B[39;00m\n\u001B[0;32m--> 302\u001B[0m     inferred_reqs \u001B[38;5;241m=\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodels\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minfer_pip_requirements\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    303\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_data_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    304\u001B[0m \u001B[43m        \u001B[49m\u001B[43mFLAVOR_NAME\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    305\u001B[0m \u001B[43m        \u001B[49m\u001B[43mfallback\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_reqs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    306\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    307\u001B[0m     default_reqs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msorted\u001B[39m(\u001B[38;5;28mset\u001B[39m(inferred_reqs)\u001B[38;5;241m.\u001B[39munion(default_reqs))\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/environment.py:390\u001B[0m, in \u001B[0;36minfer_pip_requirements\u001B[0;34m(model_uri, flavor, fallback)\u001B[0m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;124;03mInfers the pip requirements of the specified model by creating a subprocess and loading\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03mthe model in it to determine which packages are imported.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;124;03m:return: A list of inferred pip requirements (e.g. ``[\"scikit-learn==0.24.2\", ...]``).\u001B[39;00m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    389\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 390\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_infer_requirements\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    391\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[1;32m    392\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m fallback \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py:371\u001B[0m, in \u001B[0;36m_infer_requirements\u001B[0;34m(model_uri, flavor)\u001B[0m\n\u001B[1;32m    368\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _PYPI_PACKAGE_INDEX \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    369\u001B[0m     _PYPI_PACKAGE_INDEX \u001B[38;5;241m=\u001B[39m _load_pypi_package_index()\n\u001B[0;32m--> 371\u001B[0m modules \u001B[38;5;241m=\u001B[39m \u001B[43m_capture_imported_modules\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mflavor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    372\u001B[0m packages \u001B[38;5;241m=\u001B[39m _flatten([_MODULES_TO_PACKAGES\u001B[38;5;241m.\u001B[39mget(module, []) \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m modules])\n\u001B[1;32m    373\u001B[0m packages \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m(\u001B[38;5;28mmap\u001B[39m(_normalize_package_name, packages))\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py:274\u001B[0m, in \u001B[0;36m_capture_imported_modules\u001B[0;34m(model_uri, flavor)\u001B[0m\n\u001B[1;32m    268\u001B[0m \u001B[38;5;66;03m# Reset the path variable from the main process so that the subprocess retains all\u001B[39;00m\n\u001B[1;32m    269\u001B[0m \u001B[38;5;66;03m# main process configuration that a user has.\u001B[39;00m\n\u001B[1;32m    270\u001B[0m \u001B[38;5;66;03m# See: ``https://github.com/mlflow/mlflow/issues/6905`` for context on minio configuration\u001B[39;00m\n\u001B[1;32m    271\u001B[0m \u001B[38;5;66;03m# resolution in a subprocess based on PATH entries.\u001B[39;00m\n\u001B[1;32m    272\u001B[0m main_env[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPATH\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m/usr/sbin:/sbin:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m main_env[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPATH\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[0;32m--> 274\u001B[0m \u001B[43m_run_command\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[43m    \u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m    276\u001B[0m \u001B[43m        \u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecutable\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    277\u001B[0m \u001B[43m        \u001B[49m\u001B[43m_capture_modules\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;18;43m__file__\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--model-path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlocal_model_path\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--flavor\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mflavor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--output-file\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43moutput_file\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m--sys-path\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mjson\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdumps\u001B[49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout_seconds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mprocess_timeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    288\u001B[0m \u001B[43m    \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmain_env\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    289\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    290\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(output_file) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[1;32m    291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39mread()\u001B[38;5;241m.\u001B[39msplitlines()\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/utils/requirements_utils.py:201\u001B[0m, in \u001B[0;36m_run_command\u001B[0;34m(cmd, timeout_seconds, env)\u001B[0m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    200\u001B[0m     timer\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m--> 201\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[43mproc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcommunicate\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    202\u001B[0m     stdout \u001B[38;5;241m=\u001B[39m stdout\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    203\u001B[0m     stderr \u001B[38;5;241m=\u001B[39m stderr\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/subprocess.py:1154\u001B[0m, in \u001B[0;36mPopen.communicate\u001B[0;34m(self, input, timeout)\u001B[0m\n\u001B[1;32m   1151\u001B[0m     endtime \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1153\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1154\u001B[0m     stdout, stderr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_communicate\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mendtime\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1155\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyboardInterrupt\u001B[39;00m:\n\u001B[1;32m   1156\u001B[0m     \u001B[38;5;66;03m# https://bugs.python.org/issue25942\u001B[39;00m\n\u001B[1;32m   1157\u001B[0m     \u001B[38;5;66;03m# See the detailed comment in .wait().\u001B[39;00m\n\u001B[1;32m   1158\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/subprocess.py:2005\u001B[0m, in \u001B[0;36mPopen._communicate\u001B[0;34m(self, input, endtime, orig_timeout)\u001B[0m\n\u001B[1;32m   1998\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timeout(endtime, orig_timeout,\n\u001B[1;32m   1999\u001B[0m                         stdout, stderr,\n\u001B[1;32m   2000\u001B[0m                         skip_check_and_raise\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   2001\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(  \u001B[38;5;66;03m# Impossible :)\u001B[39;00m\n\u001B[1;32m   2002\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m   2003\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfailed to raise TimeoutExpired.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m-> 2005\u001B[0m ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2006\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001B[1;32m   2008\u001B[0m \u001B[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001B[39;00m\n\u001B[1;32m   2009\u001B[0m \u001B[38;5;66;03m# objects; they are no longer using C stdio!\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/selectors.py:416\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    414\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    415\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 416\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "\n",
    "# Bayesian\n",
    "n_iter = 5\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "    }\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "searcher_bayes = BayesSearchCV(estimator=rf,\n",
    "                    search_spaces=params,\n",
    "                    n_iter=n_iter,\n",
    "                    random_state=123)\n",
    "\n",
    "with mlflow.start_run(run_name=\"autolog_with_grid_search\") as run:\n",
    "    searcher_bayes.fit(X_train, y_train)\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:15.826708Z",
     "start_time": "2023-05-06T04:12:15.824875Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:32.933350Z",
     "start_time": "2023-05-06T04:12:16.250743Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/06 04:12:16 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n",
      "2023/05/06 04:12:32 INFO mlflow.sklearn.utils: Logging the 5 best runs, 22 runs will be omitted.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# load dataset\n",
    "db = load_wine()\n",
    "\n",
    "# define train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)\n",
    "\n",
    "# connect to mlflow\n",
    "mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")\n",
    "mlflow.set_experiment(\"mlflow_tracking_with_autolog\")\n",
    "\n",
    "\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "\n",
    "params = {\n",
    "  \"n_estimators\": [33, 66, 200],\n",
    "  \"max_depth\": [2, 4, 6],\n",
    "  \"max_features\": [3, 4, 5]\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor()\n",
    "searcher = GridSearchCV(estimator=rf, param_grid=params)\n",
    "\n",
    "with mlflow.start_run(run_name=\"run_3\") as run:\n",
    "    searcher.fit(X_train, y_train)\n",
    "mlflow.end_run() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute a model stored as an artifact inside a run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:34.456931Z",
     "start_time": "2023-05-06T04:12:32.940687Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/06 04:12:33 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"model_to_predict\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=10, max_features=10)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    run_id = run.info.run_id\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also use the UI or the API to get the relevant information for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:34.501989Z",
     "start_time": "2023-05-06T04:12:34.462021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: runs:/9154f6fbee314fe8b30d057236cdc6b9/model\n",
      "Showing predictions\n",
      "[0.01 1.06 1.   1.07 1.14 1.   0.7  1.02 1.87 1.   1.78 1.99 1.03 0.\n",
      " 0.87 0.89 1.98 1.71 1.84 0.   1.97 1.   0.   0.04 0.01 1.03 1.95 0.99\n",
      " 1.78 1.99 0.13 1.57 1.03 0.96 0.99 0.16 2.   0.58 1.68 1.   0.   0.\n",
      " 0.02 1.   2.  ]\n"
     ]
    }
   ],
   "source": [
    "# get model path from run id \n",
    "\n",
    "model_path = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# load using sklearn flavor\n",
    "loaded_model = mlflow.sklearn.load_model(model_path)\n",
    "\n",
    "print(\"Showing predictions\")\n",
    "print(loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if the frameork where we are going to use our model is not scikit, e.g. could be PyTorch or Tensorflow. We can call the model using an abstract function, so that if you now change the flavour of your model, you don't need to use any if statement or change the method of your class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:34.546268Z",
     "start_time": "2023-05-06T04:12:34.505910Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: runs:/9154f6fbee314fe8b30d057236cdc6b9/model\n",
      "Showing predictions\n",
      "[0.01 1.06 1.   1.07 1.14 1.   0.7  1.02 1.87 1.   1.78 1.99 1.03 0.\n",
      " 0.87 0.89 1.98 1.71 1.84 0.   1.97 1.   0.   0.04 0.01 1.03 1.95 0.99\n",
      " 1.78 1.99 0.13 1.57 1.03 0.96 0.99 0.16 2.   0.58 1.68 1.   0.   0.\n",
      " 0.02 1.   2.  ]\n"
     ]
    }
   ],
   "source": [
    "# get model path from run id \n",
    "\n",
    "model_path = f\"runs:/{run_id}/model\"\n",
    "print(f\"Loading model from: {model_path}\")\n",
    "\n",
    "# load using abstract flavor\n",
    "loaded_model = mlflow.pyfunc.load_model(model_path)\n",
    "\n",
    "print(\"Showing predictions\")\n",
    "print(loaded_model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, what if you want to use an unsupported framework or any different logic of prediction? \n",
    "\n",
    "We can creat a custom model by extending mlflow.pyfunc.PythonModel, with 2 methods: load_context (responsible for loading the ML artifacts) and predict. \n",
    "\n",
    "I am going to use one example from MLFlow community the VADER sentiment analysis (ADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:12:35.604674Z",
     "start_time": "2023-05-06T04:12:34.549001Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/06 04:12:34 INFO mlflow.tracking.fluent: Experiment with name 'sentiment_analysis' does not exist. Creating a new experiment.\n",
      "2023/05/06 04:12:34 INFO mlflow.tracking.fluent: Autologging successfully enabled for sklearn.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import pandas as pd\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# create an MLflow-compliant model by extending PythonModel\n",
    "class TextAnalyzerModel(mlflow.pyfunc.PythonModel):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self._analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "    def _preprocess(self):\n",
    "        pass\n",
    "\n",
    "    def _score(self, txt):\n",
    "        prediction_scores = self._analyser.polarity_scores(txt)\n",
    "        return prediction_scores\n",
    "\n",
    "    def predict(self, context, model_input):\n",
    "        model_output = model_input.apply(lambda col: self._score(col))\n",
    "        return model_output\n",
    "\n",
    "# connect to mlflow and set experiment\n",
    "mlflow.set_tracking_uri(\"http://mlflow-starter-server:5000\")\n",
    "mlflow.set_experiment(\"sentiment_analysis\")\n",
    "\n",
    "# enable autolog\n",
    "mlflow.autolog(log_model_signatures=True, log_input_examples=True)\n",
    "\n",
    "model_artifact_path = \"vader_model\"\n",
    "model = TextAnalyzerModel()\n",
    "\n",
    "# execute run\n",
    "with mlflow.start_run(run_name=\"Vader Sentiment Analysis\") as run:\n",
    "    mlflow.log_param(\"algorithm\", \"VADER\")\n",
    "    mlflow.pyfunc.log_model(artifact_path=model_artifact_path, \n",
    "                          python_model=model)\n",
    "    run_id = run.info.run_id\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After creating the the new experiment and run, we can load the model and make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T04:13:20.324971Z",
     "start_time": "2023-05-06T04:13:20.221635Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<This is a bad class. I hate MLOps and the professor! :-C. But our campus is good.> -- {'neg': 0.215, 'neu': 0.616, 'pos': 0.169, 'compound': 0.1386}\n",
      "<Lovely weather during the weekend.> -- {'neg': 0.0, 'neu': 0.513, 'pos': 0.487, 'compound': 0.5859}\n",
      "<LOL, this guy fell off a chair while listening the professor.> -- {'neg': 0.0, 'neu': 0.739, 'pos': 0.261, 'compound': 0.5473}\n",
      "<This is INSANE! How can you do such TERRIBLE thing?????> -- {'neg': 0.516, 'neu': 0.484, 'pos': 0.0, 'compound': -0.8597}\n"
     ]
    }
   ],
   "source": [
    "model_uri = f\"runs:/{run_id}/vader_model\"\n",
    "\n",
    "loaded_model = mlflow.pyfunc.load_model(model_uri)\n",
    "\n",
    "queries = [\"This is a bad class. I hate MLOps and the professor! :-C. But our campus is good.\",\n",
    "           \"Lovely weather during the weekend.\",\n",
    "           \"LOL, this guy fell off a chair while listening the professor.\",\n",
    "           \"This is INSANE! How can you do such TERRIBLE thing?????\"]\n",
    "\n",
    "for q in queries:\n",
    "    m_input = pd.DataFrame([q])\n",
    "    scores = loaded_model.predict(m_input)\n",
    "    print(f\"<{q}> -- {str(scores[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final step: let's registry our model. Why ? If you keep evolving a model, you’ll need to know which version is in production. You have to implement here the logic of champion and challenger, tested model, ready for deploy, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T02:20:45.359612Z",
     "start_time": "2023-05-06T02:20:42.035643Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'my_registered_model_1' already exists. Creating a new version of this model...\n",
      "2023/05/06 02:20:45 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: my_registered_model_1, version 2\n",
      "Created version '2' of model 'my_registered_model_1'.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name=\"log_and_register\") as run:\n",
    "    rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    mlflow.sklearn.log_model(\n",
    "    sk_model=rf,\n",
    "    artifact_path=\"sklearn-model\",\n",
    "    registered_model_name=\"my_registered_model_1\")\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this version of the model, directly from the model registry, you only need to change the path, i.e. change the source from runs to models :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T02:20:45.477144Z",
     "start_time": "2023-05-06T02:20:45.350132Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_version = 1\n",
    "model_path = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T02:20:45.530176Z",
     "start_time": "2023-05-06T02:20:45.484115Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Showing predictions\n",
      "[1.52000000e+00 1.64000000e+00 1.11111111e-02 1.20000000e-01\n",
      " 1.01000000e+00 6.25000000e-02 9.80000000e-01 0.00000000e+00\n",
      " 1.00000000e+00 1.96000000e+00 0.00000000e+00 1.14000000e+00\n",
      " 1.54000000e+00 1.03000000e+00 1.99000000e+00 0.00000000e+00\n",
      " 0.00000000e+00 1.00000000e-02 2.00000000e-02 1.00000000e-02\n",
      " 1.96000000e+00 4.33333333e-02 1.90000000e+00 0.00000000e+00\n",
      " 1.11111111e-03 9.53333333e-01 9.50000000e-01 1.00000000e+00\n",
      " 9.90000000e-01 1.00000000e-02 1.02000000e+00 2.33333333e-02\n",
      " 1.11111111e-02 0.00000000e+00 4.33333333e-02 7.27500000e-01\n",
      " 1.11000000e+00 9.70000000e-01 1.00000000e+00 0.00000000e+00\n",
      " 9.90000000e-01 9.90000000e-01 1.97000000e+00 1.11111111e-03\n",
      " 9.90000000e-01]\n"
     ]
    }
   ],
   "source": [
    "print(\"Showing predictions\")\n",
    "print(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can clearly distinguish the version of the model: \n",
    "- which is in production (Production); \n",
    "- which is being tested (Staging); \n",
    "- which has been decommissioned (Archived);\n",
    "- which has just been generated (None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T02:20:47.863786Z",
     "start_time": "2023-05-06T02:20:47.823220Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_path = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "end_time": "2023-05-06T02:20:49.147023Z",
     "start_time": "2023-05-06T02:20:49.005246Z"
    }
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "No versions of model with name 'my_registered_model_1' and stage 'staging' found",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMlflowException\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[28], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m model_name \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmy_registered_model_1\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m      2\u001B[0m model_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmodels:/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mmodel_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/staging\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m----> 4\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmlflow\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpyfunc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/pyfunc/__init__.py:577\u001B[0m, in \u001B[0;36mload_model\u001B[0;34m(model_uri, suppress_warnings, dst_path)\u001B[0m\n\u001B[1;32m    549\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mload_model\u001B[39m(\n\u001B[1;32m    550\u001B[0m     model_uri: \u001B[38;5;28mstr\u001B[39m,\n\u001B[1;32m    551\u001B[0m     suppress_warnings: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[1;32m    552\u001B[0m     dst_path: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m    553\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m PyFuncModel:\n\u001B[1;32m    554\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    555\u001B[0m \u001B[38;5;124;03m    Load a model stored in Python function format.\u001B[39;00m\n\u001B[1;32m    556\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    575\u001B[0m \u001B[38;5;124;03m                     path will be created.\u001B[39;00m\n\u001B[1;32m    576\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 577\u001B[0m     local_path \u001B[38;5;241m=\u001B[39m \u001B[43m_download_artifact_from_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel_uri\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moutput_path\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdst_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    579\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m suppress_warnings:\n\u001B[1;32m    580\u001B[0m         _warn_dependency_requirement_mismatches(local_path)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/tracking/artifact_utils.py:100\u001B[0m, in \u001B[0;36m_download_artifact_from_uri\u001B[0;34m(artifact_uri, output_path)\u001B[0m\n\u001B[1;32m     94\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;124;03m:param artifact_uri: The *absolute* URI of the artifact to download.\u001B[39;00m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;124;03m:param output_path: The local filesystem path to which to download the artifact. If unspecified,\u001B[39;00m\n\u001B[1;32m     97\u001B[0m \u001B[38;5;124;03m                    a local output path will be created.\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     99\u001B[0m root_uri, artifact_path \u001B[38;5;241m=\u001B[39m _get_root_uri_and_artifact_path(artifact_uri)\n\u001B[0;32m--> 100\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mroot_uri\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdownload_artifacts(\n\u001B[1;32m    101\u001B[0m     artifact_path\u001B[38;5;241m=\u001B[39martifact_path, dst_path\u001B[38;5;241m=\u001B[39moutput_path\n\u001B[1;32m    102\u001B[0m )\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:106\u001B[0m, in \u001B[0;36mget_artifact_repository\u001B[0;34m(artifact_uri)\u001B[0m\n\u001B[1;32m     96\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_artifact_repository\u001B[39m(artifact_uri):\n\u001B[1;32m     97\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get an artifact repository from the registry based on the scheme of artifact_uri\u001B[39;00m\n\u001B[1;32m     98\u001B[0m \n\u001B[1;32m     99\u001B[0m \u001B[38;5;124;03m    :param artifact_uri: The artifact store URI. This URI is used to select which artifact\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[38;5;124;03m             requirements.\u001B[39;00m\n\u001B[1;32m    105\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 106\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_artifact_repository_registry\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_artifact_repository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/artifact_repository_registry.py:72\u001B[0m, in \u001B[0;36mArtifactRepositoryRegistry.get_artifact_repository\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m repository \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     66\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\n\u001B[1;32m     67\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCould not find a registered artifact repository for: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     68\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCurrently registered schemes are: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\n\u001B[1;32m     69\u001B[0m             artifact_uri, \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_registry\u001B[38;5;241m.\u001B[39mkeys())\n\u001B[1;32m     70\u001B[0m         )\n\u001B[1;32m     71\u001B[0m     )\n\u001B[0;32m---> 72\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrepository\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:44\u001B[0m, in \u001B[0;36mModelsArtifactRepository.__init__\u001B[0;34m(self, artifact_uri)\u001B[0m\n\u001B[1;32m     42\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m DatabricksModelsArtifactRepository(artifact_uri)\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 44\u001B[0m     uri \u001B[38;5;241m=\u001B[39m \u001B[43mModelsArtifactRepository\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_underlying_uri\u001B[49m\u001B[43m(\u001B[49m\u001B[43martifact_uri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     45\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrepo \u001B[38;5;241m=\u001B[39m get_artifact_repository(uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/models_artifact_repo.py:78\u001B[0m, in \u001B[0;36mModelsArtifactRepository.get_underlying_uri\u001B[0;34m(uri)\u001B[0m\n\u001B[1;32m     74\u001B[0m databricks_profile_uri \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m     75\u001B[0m     get_databricks_profile_uri_from_artifact_uri(uri) \u001B[38;5;129;01mor\u001B[39;00m mlflow\u001B[38;5;241m.\u001B[39mget_registry_uri()\n\u001B[1;32m     76\u001B[0m )\n\u001B[1;32m     77\u001B[0m client \u001B[38;5;241m=\u001B[39m MlflowClient(registry_uri\u001B[38;5;241m=\u001B[39mdatabricks_profile_uri)\n\u001B[0;32m---> 78\u001B[0m (name, version) \u001B[38;5;241m=\u001B[39m \u001B[43mget_model_name_and_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muri\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m download_uri \u001B[38;5;241m=\u001B[39m client\u001B[38;5;241m.\u001B[39mget_model_version_download_uri(name, version)\n\u001B[1;32m     80\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m add_databricks_profile_info_to_artifact_uri(download_uri, databricks_profile_uri)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:94\u001B[0m, in \u001B[0;36mget_model_name_and_version\u001B[0;34m(client, models_uri)\u001B[0m\n\u001B[1;32m     92\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m model_alias \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     93\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model_name, client\u001B[38;5;241m.\u001B[39mget_model_version_by_alias(model_name, model_alias)\u001B[38;5;241m.\u001B[39mversion\n\u001B[0;32m---> 94\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m model_name, \u001B[38;5;28mstr\u001B[39m(\u001B[43m_get_latest_model_version\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel_stage\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/mlflow/store/artifact/utils/models.py:35\u001B[0m, in \u001B[0;36m_get_latest_model_version\u001B[0;34m(client, name, stage)\u001B[0m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(latest) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m     34\u001B[0m     stage_str \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m stage \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m and stage \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m---> 35\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m MlflowException(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo versions of model with name \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mstage_str\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m found\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;28mint\u001B[39m(x\u001B[38;5;241m.\u001B[39mversion) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m latest)\n",
      "\u001B[0;31mMlflowException\u001B[0m: No versions of model with name 'my_registered_model_1' and stage 'staging' found"
     ]
    }
   ],
   "source": [
    "model_name = \"my_registered_model_1\"\n",
    "model_path = f\"models:/{model_name}/staging\"\n",
    "\n",
    "model = mlflow.pyfunc.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

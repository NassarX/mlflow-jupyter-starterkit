version: '3.9'

services:
  mlflow-starter-app:
    container_name: mlflow-starter-app
    build:
      context: ./docker/app
      args:
        - PYTHON_VERSION=${PYTHON_VERSION}
        - DEBIAN_VERSION=${DEBIAN_VERSION}
        - MLFLOW_VERSION=${MLFLOW_VERSION}
        - MLFLOW_SERVER_PORT=${MLFLOW_SERVER_PORT}
    image: "nassarx/airbnb-nlp-app:1.0"
    #restart: always
    volumes:
      - ./app:/code/app
      - ./models:/code/models
    ports:
      - "80:80"
      - "5678:5678"
    depends_on:
      - mlflow-starter-server

  mlflow-starter-notebook:
    container_name: mlflow-starter-notebook
    build:
      context: ./docker/jupyter
      args:
        - JUPYTER_BASE_IMAGE=${JUPYTER_BASE_IMAGE}
        - JUPYTER_BASE_VERSION=${JUPYTER_BASE_VERSION}
    image: "nassarx/mlflow-starter-notebook:1.0"
    ports:
      - "${JUPYTER_HOST_PORT}:${JUPYTER_PORT}"
    environment:
      GRANT_SUDO: "yes"
    user: "root"
    command: "start-notebook.sh --NotebookApp.token=${JUPYTER_TOKEN}"
    volumes:
      - ./notebooks:/home/jovyan/work
      - ./mlruns:/home/jovyan/mlruns
    depends_on:
      - mlflow-starter-server

  mlflow-starter-server:
    container_name: mlflow-starter-server
    build:
      context: ./docker/mlflow
      args:
        - PYTHON_VERSION=${PYTHON_VERSION}
        - DEBIAN_VERSION=${DEBIAN_VERSION}
        - MLFLOW_VERSION=${MLFLOW_VERSION}
        - MLFLOW_SERVER_PORT=${MLFLOW_SERVER_PORT}
    image: "nassarx/mlflow-starter-server:1.0"
    environment:
      - MLFLOW_BACKEND_STORE=${MLFLOW_BACKEND_STORE}
      - MLFLOW_TRACKING_URI=${MLFLOW_TRACKING_URI}
    expose:
      - "${MLFLOW_SERVER_PORT}"
    ports:
      - "${MLFLOW_SERVER_HOST_PORT}:${MLFLOW_SERVER_PORT}"
    volumes:
      - ./mlruns:${MLFLOW_TRACKING_URI} # as models are not saved locally like metadata, we need to mount the mlruns from mlflow server itself

networks:
  default:
    name: mlflow-starter